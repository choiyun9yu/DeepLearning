{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.168-py3-none-any.whl (613 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m613.8/613.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (1.4.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (4.7.0.68)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (5.9.4)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (1.9.1)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Collecting py-cpuinfo\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (9.2.0)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (3.5.3)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from ultralytics) (0.14.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from matplotlib>=3.2.2->ultralytics) (22.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from matplotlib>=3.2.2->ultralytics) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from matplotlib>=3.2.2->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from matplotlib>=3.2.2->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from matplotlib>=3.2.2->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from pandas>=1.1.4->ultralytics) (2022.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from requests>=2.23.0->ultralytics) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from requests>=2.23.0->ultralytics) (2.1.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from torch>=1.8.0->ultralytics) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->ultralytics) (1.15.0)\n",
      "Installing collected packages: py-cpuinfo, seaborn, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 seaborn-0.12.2 ultralytics-8.0.168\n"
     ]
    }
   ],
   "source": [
    "# # yolo v8 을 사용하기 위해서 설치\n",
    "# !pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained model load\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo v8 부터는 터미널이 아니어도 실행\n",
    "cap = cv2.VideoCapture(0)   # 0번 카메라 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 54.7ms\n",
      "Speed: 2.2ms preprocess, 54.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.9ms\n",
      "Speed: 1.7ms preprocess, 49.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.3ms\n",
      "Speed: 1.8ms preprocess, 59.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.1ms\n",
      "Speed: 1.9ms preprocess, 52.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.6ms\n",
      "Speed: 1.9ms preprocess, 51.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.1ms\n",
      "Speed: 1.9ms preprocess, 51.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.4ms\n",
      "Speed: 2.3ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 chair, 51.4ms\n",
      "Speed: 1.8ms preprocess, 51.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.0ms\n",
      "Speed: 1.8ms preprocess, 51.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.6ms\n",
      "Speed: 2.4ms preprocess, 51.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.0ms\n",
      "Speed: 2.3ms preprocess, 52.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.5ms\n",
      "Speed: 1.7ms preprocess, 52.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.1ms\n",
      "Speed: 1.9ms preprocess, 50.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.5ms\n",
      "Speed: 1.9ms preprocess, 50.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.8ms\n",
      "Speed: 2.1ms preprocess, 53.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.2ms\n",
      "Speed: 1.9ms preprocess, 50.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.2ms\n",
      "Speed: 2.0ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.9ms\n",
      "Speed: 1.9ms preprocess, 52.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.2ms\n",
      "Speed: 2.4ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.1ms\n",
      "Speed: 2.1ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.8ms\n",
      "Speed: 1.8ms preprocess, 48.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.3ms\n",
      "Speed: 2.1ms preprocess, 50.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.7ms\n",
      "Speed: 1.8ms preprocess, 50.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.3ms\n",
      "Speed: 2.3ms preprocess, 54.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.8ms\n",
      "Speed: 1.7ms preprocess, 52.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.6ms\n",
      "Speed: 2.2ms preprocess, 51.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function destroyAllWindows> returned NULL without setting an error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m33\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     11\u001b[0m         cap\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m---> 12\u001b[0m         cv2\u001b[39m.\u001b[39;49mdestroyAllWindows(\u001b[39m'\u001b[39;49m\u001b[39m0\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function destroyAllWindows> returned NULL without setting an error"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    sucees, frame= cap.read()\n",
    "\n",
    "    if sucees:\n",
    "        results = model(frame)\n",
    "        # plot()  결과를 그림 그리기 위해 필요\n",
    "        annotated_frame = results[0].plot()\n",
    "        cv2.imshow('YOLOv8 Inference', annotated_frame) # imshow('title', 그릴 것)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows('YOLOv8 Inference')\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print('File is not opened')\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows('YOLOv8 Inference') \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.168 🚀 Python-3.8.15 torch-1.13.1 CPU (Apple M1 Pro)\n",
      "Setup complete ✅ (8 CPUs, 16.0 GB RAM, 181.7/460.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 80\n",
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "print(type(model.names), len(model.names))\n",
    "print(model.names)  # 모델 분류 목록 사전 자료형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyYAML in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (6.0)\n"
     ]
    }
   ],
   "source": [
    "# # yaml file control lib\n",
    "# !pip install PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# 데이터셋 yaml 설정, yaml 파일 기준 학습 데이터 읽어드림\n",
    "data = {\n",
    "    'test': '/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/test/images',\n",
    "    'train':'/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/train/images',\n",
    "    'val':'/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/valid/images', # yaml은 val 까지만 인식\n",
    "    'nc' : 7,   # number of class\n",
    "    'names' : ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']\n",
    "}\n",
    "\n",
    "with open('./data/aquarium_data/data.yaml', 'w') as f:\n",
    "    yaml.dump(data, f)  # data를 가져와서 f에 집어 넣어라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names': ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray'], 'nc': 7, 'test': '/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/test/images', 'train': '/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/train/images', 'val': '/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/valid/images'}\n"
     ]
    }
   ],
   "source": [
    "# 데이터 읽어드림\n",
    "with open('./data/aquarium_data/data.yaml', 'r') as f:\n",
    "    aquarium_yaml = yaml.safe_load(f)\n",
    "    print(aquarium_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.168 🚀 Python-3.8.15 torch-1.13.1 CPU (Apple M1 Pro)\n",
      "WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/data.yaml, epochs=100, patience=30, batch=32, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=/opt/homebrew/runs/detect/train6\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012213 parameters, 3012197 gradients\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/tensorboard/compat/__init__.py:42\u001b[0m, in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtensorboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m notf  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/tensorboard/compat/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:511: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n",
      "WARNING ⚠️ TensorBoard not initialized correctly, not logging this run. module 'numpy' has no attribute 'object'.\n",
      "`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n",
      "    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/train/labels... 448 images, 1 backgrounds, 0 corrupt: 100%|██████████| 448/448 [00:00<00:00, 2798.64it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/valid/labels... 127 images, 0 backgrounds, 0 corrupt: 100%|██████████| 127/127 [00:00<00:00, 3175.38it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/valid/labels.cache\n",
      "Plotting labels to /opt/homebrew/runs/detect/train6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/opt/homebrew/runs/detect/train6\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/100         0G      1.665      4.222      1.286        361        416: 100%|██████████| 14/14 [01:17<00:00,  5.55s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:10<00:00,  5.15s/it]\n",
      "                   all        127        909    0.00458      0.262     0.0312     0.0174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100         0G      1.714      3.748        1.2        410        416:  29%|██▊       | 4/14 [00:27<01:08,  6.84s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/data.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      2\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m             patience\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m             batch\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m             imgsz\u001b[39m=\u001b[39;49m\u001b[39m416\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# Note dataset download directory is '/opt/homebrew/datasets'. You can update this in '/Users/yun9yu/Library/Application Support/Ultralytics/settings.yaml'\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/ultralytics/engine/model.py:341\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    340\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    342\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/ultralytics/engine/trainer.py:196\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/ultralytics/engine/trainer.py:356\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss \u001b[39m*\u001b[39m i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_items) \u001b[39m/\u001b[39m (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtloss \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \\\n\u001b[1;32m    353\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_items\n\u001b[1;32m    355\u001b[0m \u001b[39m# Backward\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscaler\u001b[39m.\u001b[39;49mscale(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss)\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    358\u001b[0m \u001b[39m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39mif\u001b[39;00m ni \u001b[39m-\u001b[39m last_opt_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccumulate:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train(data='/Users/yun9yu/Documents/Git-Hub/DeepLearning/aidalabs/buttonCrackProject/data/aquarium_data/data.yaml',\n",
    "            epochs=100,\n",
    "            patience=30,\n",
    "            batch=32,\n",
    "            imgsz=416)\n",
    "\n",
    "# Note dataset download directory is '/opt/homebrew/datasets'. You can update this in '/Users/yun9yu/Library/Application Support/Ultralytics/settings.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Button_F_B_00.json',\n",
       " 'Button_F_B_01.json',\n",
       " 'Button_F_B_02.json',\n",
       " 'Button_F_B_03.json',\n",
       " 'Button_F_B_04.json',\n",
       " 'Button_F_B_05.json',\n",
       " 'Button_F_B_06.json',\n",
       " 'Button_F_B_07.json',\n",
       " 'Button_F_B_08.json',\n",
       " 'Button_F_B_09.json',\n",
       " 'Button_F_B_10.json',\n",
       " 'Button_F_B_11.json',\n",
       " 'Button_F_B_12.json',\n",
       " 'Button_F_B_13.json',\n",
       " 'Button_F_B_14.json',\n",
       " 'Button_F_B_15.json',\n",
       " 'Button_F_B_16.json',\n",
       " 'Button_F_B_17.json',\n",
       " 'Button_F_B_18.json',\n",
       " 'Button_F_B_19.json',\n",
       " 'Button_F_B_20.json',\n",
       " 'Button_F_B_21.json',\n",
       " 'Button_F_B_22.json',\n",
       " 'Button_F_B_23.json',\n",
       " 'Button_F_B_24.json',\n",
       " 'Button_F_B_25.json',\n",
       " 'Button_F_B_26.json',\n",
       " 'Button_F_B_27.json',\n",
       " 'Button_F_B_28.json',\n",
       " 'Button_F_B_29.json',\n",
       " 'Button_F_B_30.json',\n",
       " 'Button_F_B_31.json',\n",
       " 'Button_F_B_32.json',\n",
       " 'Button_F_B_33.json',\n",
       " 'Button_F_B_34.json',\n",
       " 'Button_F_B_35.json',\n",
       " 'Button_F_B_36.json',\n",
       " 'Button_F_B_37.json',\n",
       " 'Button_F_B_38.json',\n",
       " 'Button_F_B_39.json',\n",
       " 'Button_F_B_40.json',\n",
       " 'Button_F_B_41.json',\n",
       " 'Button_F_B_42.json',\n",
       " 'Button_F_B_43.json',\n",
       " 'Button_F_B_44.json',\n",
       " 'Button_F_B_45.json',\n",
       " 'Button_F_B_46.json',\n",
       " 'Button_F_B_47.json',\n",
       " 'Button_F_B_48.json',\n",
       " 'Button_F_B_49.json',\n",
       " 'Button_F_W_50.json',\n",
       " 'Button_F_W_51.json',\n",
       " 'Button_F_W_52.json',\n",
       " 'Button_F_W_53.json',\n",
       " 'Button_F_W_54.json',\n",
       " 'Button_F_W_55.json',\n",
       " 'Button_F_W_56.json',\n",
       " 'Button_F_W_57.json',\n",
       " 'Button_F_W_58.json',\n",
       " 'Button_F_W_59.json',\n",
       " 'Button_F_W_60.json',\n",
       " 'Button_F_W_61.json',\n",
       " 'Button_F_W_62.json',\n",
       " 'Button_F_W_63.json',\n",
       " 'Button_F_W_64.json',\n",
       " 'Button_F_W_65.json',\n",
       " 'Button_F_W_66.json',\n",
       " 'Button_F_W_67.json',\n",
       " 'Button_F_W_68.json',\n",
       " 'Button_F_W_69.json',\n",
       " 'Button_F_W_70.json',\n",
       " 'Button_F_W_71.json',\n",
       " 'Button_F_W_72.json',\n",
       " 'Button_F_W_73.json',\n",
       " 'Button_F_W_74.json',\n",
       " 'Button_F_W_75.json',\n",
       " 'Button_F_W_76.json',\n",
       " 'Button_F_W_77.json',\n",
       " 'Button_F_W_78.json',\n",
       " 'Button_F_W_79.json',\n",
       " 'Button_F_W_80.json',\n",
       " 'Button_F_W_81.json',\n",
       " 'Button_F_W_82.json',\n",
       " 'Button_F_W_83.json',\n",
       " 'Button_F_W_84.json',\n",
       " 'Button_F_W_85.json',\n",
       " 'Button_F_W_86.json',\n",
       " 'Button_F_W_87.json',\n",
       " 'Button_F_W_88.json',\n",
       " 'Button_F_W_89.json',\n",
       " 'Button_F_W_90.json',\n",
       " 'Button_F_W_91.json',\n",
       " 'Button_F_W_92.json',\n",
       " 'Button_F_W_93.json',\n",
       " 'Button_F_W_94.json',\n",
       " 'Button_F_W_95.json',\n",
       " 'Button_F_W_96.json',\n",
       " 'Button_F_W_97.json',\n",
       " 'Button_F_W_98.json',\n",
       " 'Button_F_W_99.json',\n",
       " 'Button_T_B_00.json',\n",
       " 'Button_T_B_01.json',\n",
       " 'Button_T_B_02.json',\n",
       " 'Button_T_B_03.json',\n",
       " 'Button_T_B_04.json',\n",
       " 'Button_T_B_05.json',\n",
       " 'Button_T_B_06.json',\n",
       " 'Button_T_B_07.json',\n",
       " 'Button_T_B_08.json',\n",
       " 'Button_T_B_09.json',\n",
       " 'Button_T_B_10.json',\n",
       " 'Button_T_B_11.json',\n",
       " 'Button_T_B_12.json',\n",
       " 'Button_T_B_13.json',\n",
       " 'Button_T_B_14.json',\n",
       " 'Button_T_B_15.json',\n",
       " 'Button_T_B_16.json',\n",
       " 'Button_T_B_17.json',\n",
       " 'Button_T_B_18.json',\n",
       " 'Button_T_B_19.json',\n",
       " 'Button_T_B_20.json',\n",
       " 'Button_T_B_21.json',\n",
       " 'Button_T_B_22.json',\n",
       " 'Button_T_B_23.json',\n",
       " 'Button_T_B_24.json',\n",
       " 'Button_T_B_25.json',\n",
       " 'Button_T_B_26.json',\n",
       " 'Button_T_B_27.json',\n",
       " 'Button_T_B_28.json',\n",
       " 'Button_T_B_29.json',\n",
       " 'Button_T_B_30.json',\n",
       " 'Button_T_B_31.json',\n",
       " 'Button_T_B_32.json',\n",
       " 'Button_T_B_33.json',\n",
       " 'Button_T_B_34.json',\n",
       " 'Button_T_B_35.json',\n",
       " 'Button_T_B_36.json',\n",
       " 'Button_T_B_37.json',\n",
       " 'Button_T_B_38.json',\n",
       " 'Button_T_B_39.json',\n",
       " 'Button_T_B_40.json',\n",
       " 'Button_T_B_41.json',\n",
       " 'Button_T_B_42.json',\n",
       " 'Button_T_B_43.json',\n",
       " 'Button_T_B_44.json',\n",
       " 'Button_T_B_45.json',\n",
       " 'Button_T_B_46.json',\n",
       " 'Button_T_B_47.json',\n",
       " 'Button_T_B_48.json',\n",
       " 'Button_T_B_49.json',\n",
       " 'Button_T_W_50.json',\n",
       " 'Button_T_W_51.json',\n",
       " 'Button_T_W_52.json',\n",
       " 'Button_T_W_53.json',\n",
       " 'Button_T_W_54.json',\n",
       " 'Button_T_W_55.json',\n",
       " 'Button_T_W_56.json',\n",
       " 'Button_T_W_57.json',\n",
       " 'Button_T_W_58.json',\n",
       " 'Button_T_W_59.json',\n",
       " 'Button_T_W_60.json',\n",
       " 'Button_T_W_61.json',\n",
       " 'Button_T_W_62.json',\n",
       " 'Button_T_W_63.json',\n",
       " 'Button_T_W_64.json',\n",
       " 'Button_T_W_65.json',\n",
       " 'Button_T_W_66.json',\n",
       " 'Button_T_W_67.json',\n",
       " 'Button_T_W_68.json',\n",
       " 'Button_T_W_69.json',\n",
       " 'Button_T_W_70.json',\n",
       " 'Button_T_W_71.json',\n",
       " 'Button_T_W_72.json',\n",
       " 'Button_T_W_73.json',\n",
       " 'Button_T_W_74.json',\n",
       " 'Button_T_W_75.json',\n",
       " 'Button_T_W_76.json',\n",
       " 'Button_T_W_77.json',\n",
       " 'Button_T_W_78.json',\n",
       " 'Button_T_W_79.json',\n",
       " 'Button_T_W_80.json',\n",
       " 'Button_T_W_81.json',\n",
       " 'Button_T_W_82.json',\n",
       " 'Button_T_W_83.json',\n",
       " 'Button_T_W_84.json',\n",
       " 'Button_T_W_85.json',\n",
       " 'Button_T_W_86.json',\n",
       " 'Button_T_W_87.json',\n",
       " 'Button_T_W_88.json',\n",
       " 'Button_T_W_89.json',\n",
       " 'Button_T_W_90.json',\n",
       " 'Button_T_W_91.json',\n",
       " 'Button_T_W_92.json',\n",
       " 'Button_T_W_93.json',\n",
       " 'Button_T_W_94.json',\n",
       " 'Button_T_W_95.json',\n",
       " 'Button_T_W_96.json',\n",
       " 'Button_T_W_97.json',\n",
       " 'Button_T_W_98.json',\n",
       " 'Button_T_W_99.json']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "json_dir = './Fabric_Data/3_button_json/'\n",
    "json_list= [name for name in os.listdir(json_dir)]\n",
    "json_list.sort()    # 데이터셋 정렬\n",
    "json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dir = './Fabric_Data/3_button_json/'\n",
    "if not os.path.exists(label_dir):\n",
    "    os.makedir(label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n",
      "('B', '.text')\n"
     ]
    }
   ],
   "source": [
    "for name in json_list:\n",
    "    with open(json_dir + name) as file:\n",
    "        obj = json.load(file)\n",
    "\n",
    "        label = '0' if obj['label']=='false' else '1' # 0~79까지 80개는 욜로에서 사용중 그래서 덮어쓸지 뒤에 붙일지 결정해야함\n",
    "        x = obj['bbox']['x1']\n",
    "        y = obj['bbox']['y1']\n",
    "        w = obj['bbox']['x2'] - x\n",
    "        h = obj['bbox']['y2'] - y\n",
    "\n",
    "        print(os.path.splitext(name[0] + '.text'))\n",
    "        label_filename = label_dir + os.path.splitext(name)[0] + '.text'\n",
    "        wfile = open(label_filename, 'w')\n",
    "        wfile.write(f'{label} {x:f} {y:f} {w:f} {h:f}\\n')\n",
    "        wfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "\n",
    "if not os.path.exists('./dataset/bad'):\n",
    "    os.makedirs('./dataset/bad')\n",
    "if not os.path.exists('./dataset/good'):\n",
    "    os.makedirs('./dataset/good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_list = glob.glob('./Fabric_Data/button_images/Button_F*.jpg')\n",
    "for src_path in bad_list:\n",
    "    dst_path = './dataset/bad/' + os.path.basename(src_path)\n",
    "    shutil.copy2(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_list = glob.glob('./Fabric_Data/button_images/Button_T*.jpg')\n",
    "for src_path in good_list:\n",
    "    dst_path = './dataset/good/' + os.path.basename(src_path)\n",
    "    shutil.copy2(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 0 files [00:00, ? files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders as sf\n",
    "\n",
    "sf.ratio('./dataset/', output = './splited_dataset/', seed = 1357, ratio=(.8, .1, .1))\n",
    "\n",
    "dest_dir = './splited_dataset/test/bad/images/'\n",
    "file_list = os.listdir('./splited_dataset/test/')\n",
    "for src_path in file_list:\n",
    "    shutil.move(src_path, dest_dir + os.path.basename(src_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
