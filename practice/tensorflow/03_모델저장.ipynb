{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 모델 저장 및 학습 중단"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyyaml\n",
            "  Using cached PyYAML-6.0.tar.gz (124 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: h5py in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dl/lib/python3.8/site-packages (from h5py) (1.19.5)\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-6.0-cp38-cp38-macosx_11_0_arm64.whl size=45335 sha256=f51e23c439d458c175b4ad459724aef811e63bfc47ad2b2cc9ec63ad9cecea59\n",
            "  Stored in directory: /Users/yun9yuchoi/Library/Caches/pip/wheels/52/84/66/50912fd7bf1639a31758e40bd4312602e104a8eca1e0da9645\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "Successfully installed pyyaml-6.0\n"
          ]
        }
      ],
      "source": [
        "# python에서 yaml을 사용하기 위한 모듈\n",
        "!pip install pyyaml h5py"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 모델 실행 속도를 빠르게하기 위해 샘플 데이터 1000개만 사용\n",
        "train_images=train_images[:1000].reshape(-1,28*28)/255.0\n",
        "test_images=test_images[:1000].reshape(-1,28*28)/255.0\n",
        "\n",
        "train_labels=train_labels[:1000]\n",
        "test_labels=test_labels[:1000]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1 Pro\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-14 00:45:11.044719: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-02-14 00:45:11.044924: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_model():\n",
        "    model=tf.keras.Sequential([\n",
        "        keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "        keras.layers.Dropout(0.2),\n",
        "        keras.layers.Dense(10)\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "    return model\n",
        "\n",
        "model=create_model()\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 훈련하는 동안 체크포인트 저장하기\n",
        "- tf.kerass.callbacks.ModelCheckpoint 콜백을 사용하면 훈련 도중 또는 훈련 종료 시 모델을 저장할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 10ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4614 - val_sparse_categorical_accuracy: 0.8750\n",
            "INFO:tensorflow:Assets written to: model/cp.ckpt/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0017 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4717 - val_sparse_categorical_accuracy: 0.8700\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4716 - val_sparse_categorical_accuracy: 0.8740\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4719 - val_sparse_categorical_accuracy: 0.8720\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0015 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4741 - val_sparse_categorical_accuracy: 0.8740\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0014 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.8740\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4727 - val_sparse_categorical_accuracy: 0.8750\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4781 - val_sparse_categorical_accuracy: 0.8740\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4798 - val_sparse_categorical_accuracy: 0.8730\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4807 - val_sparse_categorical_accuracy: 0.8740\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x2876e6d30>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# 베스트 모델 저장 폴더\n",
        "checkpoint_path=\"model/cp.ckpt\"\n",
        "checkpoint_dir=os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 베스트 모델 저장 : 학습 중 나타난 가장 좋은 모델 저장\n",
        "MCP=ModelCheckpoint(\n",
        "    filepath=checkpoint_path,  # 파일이 저장될 경로\n",
        "    monitor='val_loss',  # train set의 loss가 가장 작을 때 'loss'를 입력 / validation set의 loss가 가장 작을 때 저장하고 싶으면 'val_loss'를 입력\n",
        "    save_best_only=True,  # 모델이 개선되었을 때만 저장\n",
        "    verbovse=1  # 진행 내용 출력\n",
        ")\n",
        "\n",
        "# 학습 중단 : 모델이 더이상 개선되지 않으면 학습 중단\n",
        "ES=EarlyStopping(\n",
        "    monitor='val_accuracy',  # 무엇을 기준으로 개선여부 판단할지 설정 분류는'val_accuracy' / 회귀는 'val_loss'\n",
        "    patience=5   # 인내 값 : 연속으로 몇번의 학습동안 모델이 개선되지 않아도 중단하지 않음\n",
        ")\n",
        "\n",
        "model.fit(train_images,train_labels,\n",
        "          epochs=10,\n",
        "          validation_data=(test_images, test_labels),\n",
        "          callbacks=[MCP,ES])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 2.3531 - sparse_categorical_accuracy: 0.0840\n",
            "Untrained, accuracy:  8.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-14 01:29:23.290053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "# 비교모델 생성\n",
        "model2 = create_model()\n",
        "loss, acc = model2.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Untrained, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4614 - sparse_categorical_accuracy: 0.8750\n",
            "Restored, accuracy: 87.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-14 01:36:22.960104: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open model/cp.ckpt: Failed precondition: model/cp.ckpt; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
          ]
        }
      ],
      "source": [
        "# 체크포인트에서 가중치를 로드하고 다시 평가\n",
        "model2.load_weights(checkpoint_path)\n",
        "loss, acc = model2.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored, accuracy: {:5.2f}%\".format(100*acc))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "46e27ede752268be201d36b7fbc2802b29a11b0bb095abacecc6c0428b93624a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
