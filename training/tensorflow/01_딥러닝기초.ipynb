{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCZgaje2NQND"
      },
      "source": [
        "# 딥러닝 개요"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 머신러닝"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "- 학습 : feature data 와 label data 간의 관계를 학습\n",
        "- MachineLearning에선 전처리가 어렵다. (domain knowlege가 필요!)\n",
        "- 이러한 어려움 때문에 DeepLearning이 나왔다 (전처리 해주면 물론 더 잘 돌아감) \n",
        "- 데이터 양이 더 많이 필요함 (근데 전처리보다 데이터 수집이 더 힘듬ㅜㅜ)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wle-OZ3DNfoU"
      },
      "source": [
        "## 환경설정"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw_3jLB-PELB"
      },
      "source": [
        "- Colab : 코드 작성, 라이브러리 연동, GPU활용\n",
        "- 구글 드라이브 : 데이터 가져오거나 저장m\n",
        "- 코랩에서 구글 드라이브에 있는 파일 접근\n",
        "  - 왼쪽의 ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAVCAYAAABVAo5cAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAADFSURBVEhL7ZQxDoQgEEVnt6TFVlvPZMklPASn0Zo72BJrWimpXYdMstFFRONaGF/yYwZm+ARwXuMEXMibvpdxf8PoHQ7DANZair7keQ6MMYr2sWqIZnVdUzSnKAo/d8R01bBtW681sizzCoEnUFUVRXM27xCLy7L8EecccK9LOedAKQVd19EKC6akIE3TjEKIUWtNI2lgPtZhfYjnPzydx/B0Ng2NMdD3fbIwP8ah1paClDLYiTabN2ovsbYXNfwHd3+lAB/XWt2ncV2RHQAAAABJRU5ErkJggg==) 아이콘 클릭\n",
        "  - 상단의 ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAUCAYAAACaq43EAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAF0SURBVEhLxZWxcoJAEIY3mTTQQgsttNhSY2uLLTyDY+072GJLLaXWttpaQ6utbZIf9uJ5Hk48JvGb2bnbHYaf3b1b3j6/oRfwzuu/8zJhban3+z1VVUV1XXPkljiOKc9z9szQZlyWZa8o2O12VBQFe2ZoM86yjHfDcF2X0jSl0WjEkSuDe+x5HgVB0JrjOBztOJ1Obct0DBZGr+fz+Y+p9LVskPBkMqHtdsteV9okSdh7jLEwygph3/fpeDxytPsYy7LY68dYWFwnZHg4HNo9sG2bxuMxe/0YCUdRRGEYsteVGFdMgKzVg6ZiJDydTnnXsdlsaL1e0+Vy4cj9MypP32NkAxNAEAbQb5RaIHq/Wq3aVeaD11+DcSlAhjDdiwFG73K5ZO+Wp0st9xKZytmryM+qPC0MMUwkDAaUVS6tDMosn3YVbY9nsxmdz2f27sEpBo+E8WFoA0bqYrHg6JXe3yIya5qGI2bgSuF0634SWuG/h+gLQMqdX30C/zgAAAAASUVORK5CYII=) 아이콘 클릭"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 텐서플로우 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FdHVdB3X1ouB"
      },
      "source": [
        "### GPU 체크하기\n",
        "- 런타임 - 런타임 유형 - GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fPz6TcV1sol",
        "outputId": "3e41ff4c-783e-4dfa-ced7-9a4501f3cacd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init Plugin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init Graph Optimizer\n",
            "Init Kernel\n"
          ]
        }
      ],
      "source": [
        "# 현재 할당된 것이 CPU인지 GPU인지 확인\n",
        "import tensorflow as tf\n",
        "tf.config.experimental.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1 Pro\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-13 23:44:54.580832: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-02-13 23:44:54.580981: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 11920769701157739838,\n",
              " name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " locality {\n",
              "   bus_id: 1\n",
              " }\n",
              " incarnation: 7702881642302318973\n",
              " physical_device_desc: \"device: 0, name: METAL, pci bus id: <undefined>\"]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 할당된 GPU 조회\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Y3H_d-W3jpM"
      },
      "outputs": [],
      "source": [
        "# 할당된 GPU 실행\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "\n",
        "if gpus:\n",
        "  try:\n",
        "    # GPU 메모리 사용 설정\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)  \n",
        "  except RuntimeError as re:\n",
        "    print(re)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w71TKGJ-33Yj",
        "outputId": "13256ea8-2e24-4b60-bcf9-e9ee25b15f04"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-13 23:45:03.264254: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-02-13 23:45:03.264274: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "# GPU 메모리를 전부 할당하지 않고 필요에 따라 자동으로 할당하도록 설정\n",
        "from tensorflow.compat.v1 import ConfigProto, InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config = config)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cv9031pd5mtn"
      },
      "source": [
        "### 설치된 라이브러리 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQ2hX8bp5UPs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "absl-py @ file:///home/conda/feedstock_root/build_artifacts/absl-py_1606234718434/work\n",
            "appnope @ file:///home/conda/feedstock_root/build_artifacts/appnope_1649077682618/work\n",
            "asttokens @ file:///home/conda/feedstock_root/build_artifacts/asttokens_1670263926556/work\n",
            "astunparse @ file:///home/conda/feedstock_root/build_artifacts/astunparse_1610696312422/work\n",
            "backcall @ file:///home/conda/feedstock_root/build_artifacts/backcall_1592338393461/work\n",
            "backports.functools-lru-cache @ file:///home/conda/feedstock_root/build_artifacts/backports.functools_lru_cache_1618230623929/work\n",
            "cached-property @ file:///home/conda/feedstock_root/build_artifacts/cached_property_1615209429212/work\n",
            "cachetools==5.3.0\n",
            "certifi==2022.12.7\n",
            "cffi @ file:///Users/runner/miniforge3/conda-bld/cffi_1671179605388/work\n",
            "charset-normalizer==3.0.1\n",
            "comm @ file:///home/conda/feedstock_root/build_artifacts/comm_1670575068857/work\n",
            "debugpy @ file:///Users/runner/miniforge3/conda-bld/debugpy_1674522474365/work\n",
            "decorator @ file:///home/conda/feedstock_root/build_artifacts/decorator_1641555617451/work\n",
            "executing @ file:///home/conda/feedstock_root/build_artifacts/executing_1667317341051/work\n",
            "flatbuffers==1.12\n",
            "gast @ file:///home/conda/feedstock_root/build_artifacts/gast_1596839682936/work\n",
            "google-auth==2.16.0\n",
            "google-auth-oauthlib==0.4.6\n",
            "google-pasta==0.2.0\n",
            "grpcio @ file:///Users/runner/miniforge3/conda-bld/grpcio_1610588581604/work\n",
            "h5py @ file:///Users/runner/miniforge3/conda-bld/h5py_1609497512060/work\n",
            "idna==3.4\n",
            "importlib-metadata @ file:///home/conda/feedstock_root/build_artifacts/importlib-metadata_1672612343532/work\n",
            "ipykernel @ file:///Users/runner/miniforge3/conda-bld/ipykernel_1676324664952/work\n",
            "ipython @ file:///Users/runner/miniforge3/conda-bld/ipython_1676047761112/work\n",
            "jedi @ file:///home/conda/feedstock_root/build_artifacts/jedi_1669134318875/work\n",
            "jupyter_client @ file:///home/conda/feedstock_root/build_artifacts/jupyter_client_1675178684608/work\n",
            "jupyter_core @ file:///Users/runner/miniforge3/conda-bld/jupyter_core_1669775245693/work\n",
            "keras-nightly==2.5.0.dev2021032900\n",
            "Keras-Preprocessing @ file:///home/conda/feedstock_root/build_artifacts/keras-preprocessing_1610713559828/work\n",
            "Markdown==3.4.1\n",
            "MarkupSafe==2.1.2\n",
            "matplotlib-inline @ file:///home/conda/feedstock_root/build_artifacts/matplotlib-inline_1660814786464/work\n",
            "nest-asyncio @ file:///home/conda/feedstock_root/build_artifacts/nest-asyncio_1664684991461/work\n",
            "numpy @ file:///Users/runner/miniforge3/conda-bld/numpy_1649281411076/work\n",
            "oauthlib==3.2.2\n",
            "opt-einsum @ file:///home/conda/feedstock_root/build_artifacts/opt_einsum_1617859230218/work\n",
            "packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1673482170163/work\n",
            "parso @ file:///home/conda/feedstock_root/build_artifacts/parso_1638334955874/work\n",
            "pexpect @ file:///home/conda/feedstock_root/build_artifacts/pexpect_1667297516076/work\n",
            "pickleshare @ file:///home/conda/feedstock_root/build_artifacts/pickleshare_1602536217715/work\n",
            "prompt-toolkit @ file:///home/conda/feedstock_root/build_artifacts/prompt-toolkit_1670414775770/work\n",
            "protobuf==3.20.3\n",
            "psutil @ file:///Users/runner/miniforge3/conda-bld/psutil_1667885969940/work\n",
            "ptyprocess @ file:///home/conda/feedstock_root/build_artifacts/ptyprocess_1609419310487/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
            "pure-eval @ file:///home/conda/feedstock_root/build_artifacts/pure_eval_1642875951954/work\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\n",
            "Pygments @ file:///home/conda/feedstock_root/build_artifacts/pygments_1672682006896/work\n",
            "python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\n",
            "pyzmq @ file:///Users/runner/miniforge3/conda-bld/pyzmq_1673612773465/work\n",
            "requests==2.28.2\n",
            "requests-oauthlib==1.3.1\n",
            "rsa==4.9\n",
            "scipy==1.9.1\n",
            "six @ file:///home/conda/feedstock_root/build_artifacts/six_1590081179328/work\n",
            "stack-data @ file:///home/conda/feedstock_root/build_artifacts/stack_data_1669632077133/work\n",
            "tensorboard==2.11.2\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-macos==2.5.0\n",
            "tensorflow-metal==0.1.2\n",
            "termcolor @ file:///home/conda/feedstock_root/build_artifacts/termcolor_1657118200573/work\n",
            "torch @ file:///Users/runner/miniforge3/conda-bld/pytorch-recipe_1660136155850/work\n",
            "tornado @ file:///Users/runner/miniforge3/conda-bld/tornado_1666788903714/work\n",
            "traitlets @ file:///home/conda/feedstock_root/build_artifacts/traitlets_1675110562325/work\n",
            "typing-extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1602702424206/work\n",
            "urllib3==1.26.14\n",
            "wcwidth @ file:///home/conda/feedstock_root/build_artifacts/wcwidth_1673864653149/work\n",
            "Werkzeug==2.2.2\n",
            "wrapt @ file:///Users/runner/miniforge3/conda-bld/wrapt_1624971819058/work\n",
            "zipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1675982654259/work\n"
          ]
        }
      ],
      "source": [
        "!pip freeze"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pQZhIv_36UpT"
      },
      "source": [
        "# Keras 프레임 워크를 이용해서 AND 논리 학습하기"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Sequential() : 신경망을 쌓는 토대 (신경망 생성) \n",
        "- Dense() : 실제 신경망 층을 설정하는 기능 (신경망에 퍼셉트론 층 추가)\n",
        "  - units : 현재 층에 존재하는 퍼셉트론의 수 (출력 수)\n",
        "  - input_dim : 입력의 수 (입력되는 feature의 수)\n",
        "- Activation() : 활성화 함수를 설정 (시그모이드, 렐루 등) \n",
        "- add() : Dense나 Activation 등을 신경망에 추가 \n",
        "- Optimizers : 최적화 함수 (경사하강법 종류)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nBFZ4Ya5USJ",
        "outputId": "7c844f73-995c-4815-db5c-93c32c02c78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Init Plugin\n",
            "Init Graph Optimizer\n",
            "Init Kernel\n",
            "Metal device set to: Apple M1 Pro\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-13 23:47:02.456523: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-02-13 23:47:02.456637: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(units =1, input_dim=2))\n",
        "model1.add(Activation(\"sigmoid\"))\n",
        "\n",
        "# 생성된 신경망의 구조를 출력\n",
        "model1.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wUWsZLkZBMrk"
      },
      "source": [
        "## 데이터 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rUCFTCuZ5UUj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "X_AND = [[0,0],[1,0],[0,1],[1,1]]\n",
        "y_AND = [0,0,0,1]\n",
        "\n",
        "X_NAND = [[0,0],[1,0],[0,1],[1,1]]\n",
        "y_NAND = [1,1,1,0]\n",
        "\n",
        "X_OR = [[0,0],[1,0],[0,1],[1,1]]\n",
        "y_OR = [0,1,1,1]\n",
        "\n",
        "X_XOR = [[0,0],[1,0],[0,1],[1,1]]\n",
        "y_XOR = [0,1,1,0]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lo8FIcQpBm5k"
      },
      "source": [
        "### 파라미터 (W, b)들의 초기값의 시드를 설정\n",
        "- 일반적으로 신경망을 생성하면 파라미터(W,b) 값은 랜덤으로 초기화\n",
        "- 항상 동일한 초기값으로 설정되도록 시드를 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7NY7eRhU5UXA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 컴파일에 사용할 파라미터  \n",
        "1. loss : 사용할 손실함수 (비용함수)\n",
        "    - 회귀 : MSE\n",
        "    - 이진분류 : binary_crossentropy\n",
        "    - 다진분류 : categorical_crossentropy\n",
        "2. optimizer : 최적화 함수 (경사하강법의 종류)\n",
        "    - GD : 경사하강법\n",
        "    - SGD : 확률적 경사하강법\n",
        "    - MSGD : 모멘텀 확률적 경사하강법\n",
        "    - adam  \n",
        "3. metrics : 평가도구 (정확도 또는 오차)\n",
        "    - 회귀 : 표기하지 않음 \n",
        "    - 분류 : accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1WE7QNMM5UZi"
      },
      "outputs": [],
      "source": [
        "# 작성한 신경망을 학습할 수 있도록 컴파일\n",
        "model1.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer = \"adam\",\n",
        "               metrics = [\"accuracy\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 학습\n",
        "- batch_size : 한 번 반복할 때 몇 개 데이터를 사용할 것인지 설정\n",
        "- epochs : 몇 번 반복할 것인지 (반복 횟 수) 즉, W,b를 몇 번 업데이트 할 것인지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hfNesZW55UcA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 164ms/step - loss: 0.7685 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7679 - accuracy: 0.5000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-13 23:47:44.778017: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2023-02-13 23:47:44.778210: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2023-02-13 23:47:44.877070: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7673 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7667 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7661 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7655 - accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7649 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7643 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7637 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7631 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7625 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7619 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7613 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7608 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7602 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7596 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7590 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7584 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7578 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7572 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7567 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7561 - accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7555 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7549 - accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7543 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7538 - accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7532 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7526 - accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7521 - accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7515 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7509 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7503 - accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7498 - accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7492 - accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7487 - accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7481 - accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7475 - accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7470 - accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7464 - accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7458 - accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7453 - accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7447 - accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7442 - accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7436 - accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7431 - accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7425 - accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7420 - accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7414 - accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7409 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7403 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7398 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7393 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7387 - accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7382 - accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7376 - accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7371 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7366 - accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7360 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7355 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7350 - accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7344 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7339 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7334 - accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7329 - accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7323 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7318 - accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7313 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7308 - accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7302 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7297 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7292 - accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7287 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7282 - accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7277 - accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7272 - accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7266 - accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7261 - accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7256 - accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7251 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7246 - accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7241 - accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7236 - accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7231 - accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7226 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7221 - accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7216 - accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7211 - accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7206 - accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7201 - accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7196 - accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7191 - accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7187 - accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7182 - accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7177 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7172 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7167 - accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7162 - accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7157 - accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7153 - accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7148 - accuracy: 0.5000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x1682276d0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 학습\n",
        "model1.fit(X_AND, y_AND, batch_size=4, epochs=100)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H78mTTPbHURH"
      },
      "source": [
        "## 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHEhKli65UeU",
        "outputId": "bc1adb53-a589-4a34-a5b8-83e52a185804"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-13 23:47:50.966513: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.6835984 ],\n",
              "       [0.72067225],\n",
              "       [0.47549394],\n",
              "       [0.51982397]], dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_new = [[1,0],[1,1],[0,0],[0,1]]\n",
        "y_new = [0,1,0,0]\n",
        "pred = model1.predict(X_new)\n",
        "\n",
        "pred"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "enCVSxYDqUhY"
      },
      "source": [
        "# Keras 프레임 워크를 이용해서 XOR 논리 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n2usy0A45Ugt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "X_AND = [[0,0],[1,0],[0,1],[1,1]]\n",
        "y_AND = [0,0,0,1]\n",
        "\n",
        "X_NAND = [[0,0],[1,0],[0,1],[1,1]]\n",
        "y_NAND = [1,1,1,0]\n",
        "\n",
        "X_OR = [[0,0],[1,0],[0,1],[1,1]]\n",
        "y_OR = [0,1,1,1]\n",
        "\n",
        "X_XOR = [[0,0],[1,0],[0,1],[1,1]]\n",
        "y_XOR = [0,1,1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2kfvzx35UjD",
        "outputId": "3aa3b09a-98d3-4c23-97e8-1fcfa3bdfd65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Dense(units=1, input_dim=2))\n",
        "model2.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X5J3MkQf5Ulr"
      },
      "outputs": [],
      "source": [
        "model2.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=\"adam\",\n",
        "               metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6ZZEnEYN5UoP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.7055 - accuracy: 0.5000\n",
            "Epoch 2/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7055 - accuracy: 0.5000\n",
            "Epoch 3/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7054 - accuracy: 0.5000\n",
            "Epoch 4/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7053 - accuracy: 0.5000\n",
            "Epoch 5/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7053 - accuracy: 0.5000\n",
            "Epoch 6/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.7052 - accuracy: 0.5000\n",
            "Epoch 7/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7052 - accuracy: 0.5000\n",
            "Epoch 8/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7051 - accuracy: 0.5000\n",
            "Epoch 9/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7050 - accuracy: 0.5000\n",
            "Epoch 10/2000\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.5000"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-13 23:48:48.037215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7050 - accuracy: 0.5000\n",
            "Epoch 11/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7049 - accuracy: 0.5000\n",
            "Epoch 12/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7048 - accuracy: 0.5000\n",
            "Epoch 13/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7048 - accuracy: 0.5000\n",
            "Epoch 14/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7047 - accuracy: 0.5000\n",
            "Epoch 15/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7047 - accuracy: 0.5000\n",
            "Epoch 16/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7046 - accuracy: 0.5000\n",
            "Epoch 17/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7045 - accuracy: 0.5000\n",
            "Epoch 18/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7045 - accuracy: 0.5000\n",
            "Epoch 19/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7044 - accuracy: 0.5000\n",
            "Epoch 20/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7044 - accuracy: 0.5000\n",
            "Epoch 21/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7043 - accuracy: 0.5000\n",
            "Epoch 22/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7042 - accuracy: 0.5000\n",
            "Epoch 23/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7042 - accuracy: 0.5000\n",
            "Epoch 24/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7041 - accuracy: 0.5000\n",
            "Epoch 25/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7041 - accuracy: 0.5000\n",
            "Epoch 26/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7040 - accuracy: 0.5000\n",
            "Epoch 27/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7040 - accuracy: 0.5000\n",
            "Epoch 28/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7039 - accuracy: 0.5000\n",
            "Epoch 29/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.5000\n",
            "Epoch 30/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7038 - accuracy: 0.5000\n",
            "Epoch 31/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7037 - accuracy: 0.5000\n",
            "Epoch 32/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7037 - accuracy: 0.5000\n",
            "Epoch 33/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7036 - accuracy: 0.5000\n",
            "Epoch 34/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7036 - accuracy: 0.5000\n",
            "Epoch 35/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7035 - accuracy: 0.5000\n",
            "Epoch 36/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.5000\n",
            "Epoch 37/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7034 - accuracy: 0.5000\n",
            "Epoch 38/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7034 - accuracy: 0.5000\n",
            "Epoch 39/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7033 - accuracy: 0.5000\n",
            "Epoch 40/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7033 - accuracy: 0.5000\n",
            "Epoch 41/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7032 - accuracy: 0.5000\n",
            "Epoch 42/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7032 - accuracy: 0.5000\n",
            "Epoch 43/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7031 - accuracy: 0.5000\n",
            "Epoch 44/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7031 - accuracy: 0.5000\n",
            "Epoch 45/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7030 - accuracy: 0.5000\n",
            "Epoch 46/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7030 - accuracy: 0.5000\n",
            "Epoch 47/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7029 - accuracy: 0.5000\n",
            "Epoch 48/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7029 - accuracy: 0.5000\n",
            "Epoch 49/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7028 - accuracy: 0.5000\n",
            "Epoch 50/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7028 - accuracy: 0.5000\n",
            "Epoch 51/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7027 - accuracy: 0.5000\n",
            "Epoch 52/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7027 - accuracy: 0.5000\n",
            "Epoch 53/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7026 - accuracy: 0.5000\n",
            "Epoch 54/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7026 - accuracy: 0.5000\n",
            "Epoch 55/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7025 - accuracy: 0.5000\n",
            "Epoch 56/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7025 - accuracy: 0.5000\n",
            "Epoch 57/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7024 - accuracy: 0.5000\n",
            "Epoch 58/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7024 - accuracy: 0.5000\n",
            "Epoch 59/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7024 - accuracy: 0.5000\n",
            "Epoch 60/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7023 - accuracy: 0.5000\n",
            "Epoch 61/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7023 - accuracy: 0.5000\n",
            "Epoch 62/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7022 - accuracy: 0.5000\n",
            "Epoch 63/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7022 - accuracy: 0.5000\n",
            "Epoch 64/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7021 - accuracy: 0.5000\n",
            "Epoch 65/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7021 - accuracy: 0.5000\n",
            "Epoch 66/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7020 - accuracy: 0.5000\n",
            "Epoch 67/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7020 - accuracy: 0.5000\n",
            "Epoch 68/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7019 - accuracy: 0.5000\n",
            "Epoch 69/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7019 - accuracy: 0.5000\n",
            "Epoch 70/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7019 - accuracy: 0.5000\n",
            "Epoch 71/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7018 - accuracy: 0.5000\n",
            "Epoch 72/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7018 - accuracy: 0.5000\n",
            "Epoch 73/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.5000\n",
            "Epoch 74/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.5000\n",
            "Epoch 75/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7016 - accuracy: 0.5000\n",
            "Epoch 76/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7016 - accuracy: 0.5000\n",
            "Epoch 77/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7016 - accuracy: 0.5000\n",
            "Epoch 78/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7015 - accuracy: 0.5000\n",
            "Epoch 79/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7015 - accuracy: 0.5000\n",
            "Epoch 80/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7014 - accuracy: 0.5000\n",
            "Epoch 81/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7014 - accuracy: 0.5000\n",
            "Epoch 82/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7014 - accuracy: 0.5000\n",
            "Epoch 83/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7013 - accuracy: 0.5000\n",
            "Epoch 84/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7013 - accuracy: 0.5000\n",
            "Epoch 85/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7012 - accuracy: 0.5000\n",
            "Epoch 86/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7012 - accuracy: 0.5000\n",
            "Epoch 87/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7011 - accuracy: 0.5000\n",
            "Epoch 88/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7011 - accuracy: 0.5000\n",
            "Epoch 89/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7011 - accuracy: 0.5000\n",
            "Epoch 90/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7010 - accuracy: 0.5000\n",
            "Epoch 91/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7010 - accuracy: 0.5000\n",
            "Epoch 92/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7009 - accuracy: 0.5000\n",
            "Epoch 93/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7009 - accuracy: 0.5000\n",
            "Epoch 94/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.5000\n",
            "Epoch 95/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.5000\n",
            "Epoch 96/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.5000\n",
            "Epoch 97/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.5000\n",
            "Epoch 98/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.5000\n",
            "Epoch 99/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.5000\n",
            "Epoch 100/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7006 - accuracy: 0.5000\n",
            "Epoch 101/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7006 - accuracy: 0.5000\n",
            "Epoch 102/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7006 - accuracy: 0.5000\n",
            "Epoch 103/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7005 - accuracy: 0.5000\n",
            "Epoch 104/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7005 - accuracy: 0.5000\n",
            "Epoch 105/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7004 - accuracy: 0.5000\n",
            "Epoch 106/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7004 - accuracy: 0.5000\n",
            "Epoch 107/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.5000\n",
            "Epoch 108/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7003 - accuracy: 0.5000\n",
            "Epoch 109/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7003 - accuracy: 0.5000\n",
            "Epoch 110/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7003 - accuracy: 0.5000\n",
            "Epoch 111/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7002 - accuracy: 0.5000\n",
            "Epoch 112/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7002 - accuracy: 0.5000\n",
            "Epoch 113/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7002 - accuracy: 0.5000\n",
            "Epoch 114/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7001 - accuracy: 0.5000\n",
            "Epoch 115/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7001 - accuracy: 0.5000\n",
            "Epoch 116/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7000 - accuracy: 0.5000\n",
            "Epoch 117/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7000 - accuracy: 0.5000\n",
            "Epoch 118/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7000 - accuracy: 0.5000\n",
            "Epoch 119/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6999 - accuracy: 0.5000\n",
            "Epoch 120/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6999 - accuracy: 0.5000\n",
            "Epoch 121/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6999 - accuracy: 0.5000\n",
            "Epoch 122/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6998 - accuracy: 0.5000\n",
            "Epoch 123/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6998 - accuracy: 0.5000\n",
            "Epoch 124/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6998 - accuracy: 0.5000\n",
            "Epoch 125/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch 126/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch 127/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch 128/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6996 - accuracy: 0.5000\n",
            "Epoch 129/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6996 - accuracy: 0.5000\n",
            "Epoch 130/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6996 - accuracy: 0.5000\n",
            "Epoch 131/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.5000\n",
            "Epoch 132/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.5000\n",
            "Epoch 133/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.5000\n",
            "Epoch 134/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6994 - accuracy: 0.5000\n",
            "Epoch 135/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6994 - accuracy: 0.5000\n",
            "Epoch 136/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6994 - accuracy: 0.5000\n",
            "Epoch 137/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.5000\n",
            "Epoch 138/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.5000\n",
            "Epoch 139/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6993 - accuracy: 0.5000\n",
            "Epoch 140/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6992 - accuracy: 0.5000\n",
            "Epoch 141/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.5000\n",
            "Epoch 142/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.5000\n",
            "Epoch 143/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6991 - accuracy: 0.5000\n",
            "Epoch 144/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6991 - accuracy: 0.5000\n",
            "Epoch 145/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6991 - accuracy: 0.5000\n",
            "Epoch 146/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.5000\n",
            "Epoch 147/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.5000\n",
            "Epoch 148/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6990 - accuracy: 0.5000\n",
            "Epoch 149/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6989 - accuracy: 0.5000\n",
            "Epoch 150/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6989 - accuracy: 0.5000\n",
            "Epoch 151/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6989 - accuracy: 0.5000\n",
            "Epoch 152/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6988 - accuracy: 0.5000\n",
            "Epoch 153/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6988 - accuracy: 0.5000\n",
            "Epoch 154/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.5000\n",
            "Epoch 155/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6988 - accuracy: 0.5000\n",
            "Epoch 156/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6987 - accuracy: 0.5000\n",
            "Epoch 157/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6987 - accuracy: 0.5000\n",
            "Epoch 158/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6987 - accuracy: 0.5000\n",
            "Epoch 159/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.5000\n",
            "Epoch 160/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6986 - accuracy: 0.5000\n",
            "Epoch 161/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.5000\n",
            "Epoch 162/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6985 - accuracy: 0.5000\n",
            "Epoch 163/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6985 - accuracy: 0.5000\n",
            "Epoch 164/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6985 - accuracy: 0.5000\n",
            "Epoch 165/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6985 - accuracy: 0.5000\n",
            "Epoch 166/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch 167/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch 168/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch 169/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6983 - accuracy: 0.5000\n",
            "Epoch 170/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6983 - accuracy: 0.5000\n",
            "Epoch 171/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6983 - accuracy: 0.5000\n",
            "Epoch 172/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6983 - accuracy: 0.5000\n",
            "Epoch 173/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6982 - accuracy: 0.5000\n",
            "Epoch 174/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6982 - accuracy: 0.5000\n",
            "Epoch 175/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6982 - accuracy: 0.5000\n",
            "Epoch 176/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6981 - accuracy: 0.5000\n",
            "Epoch 177/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6981 - accuracy: 0.5000\n",
            "Epoch 178/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6981 - accuracy: 0.5000\n",
            "Epoch 179/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6981 - accuracy: 0.5000\n",
            "Epoch 180/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6980 - accuracy: 0.5000\n",
            "Epoch 181/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6980 - accuracy: 0.5000\n",
            "Epoch 182/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6980 - accuracy: 0.5000\n",
            "Epoch 183/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6980 - accuracy: 0.5000\n",
            "Epoch 184/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 185/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 186/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 187/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 188/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 189/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 190/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 191/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 192/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 193/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 194/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 195/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 196/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 197/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 198/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 199/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 200/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 201/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 202/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 203/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 204/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 205/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 206/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 207/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 208/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 209/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 210/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 211/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 212/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 213/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 214/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 215/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 216/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 217/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 218/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 219/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 220/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 221/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 222/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 223/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 224/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 225/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 226/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 227/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 228/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 229/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 230/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 231/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 232/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 233/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 234/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 235/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 236/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 237/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 238/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 239/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 240/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 241/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 242/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 243/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 244/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 245/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 246/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 247/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 248/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 249/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 250/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 251/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 252/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 253/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 254/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 255/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 256/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 257/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 258/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 259/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 260/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 261/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 262/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 263/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 264/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 265/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 266/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 267/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 268/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 269/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 270/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 271/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 272/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 273/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 274/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 275/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 276/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 277/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 278/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 279/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 280/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 281/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 282/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 283/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 284/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 285/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 286/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 287/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 288/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 289/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 290/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 291/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 292/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 293/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 294/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 295/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 296/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 297/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 298/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 299/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 300/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 301/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 302/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 303/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 304/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 305/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 306/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 307/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 308/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 309/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 310/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 311/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 312/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 313/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 314/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 315/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 316/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 317/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 318/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 319/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 320/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 321/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 322/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 323/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 324/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 325/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 326/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 327/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 328/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 329/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 330/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 331/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 332/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 333/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 334/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 335/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 336/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 337/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 338/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 339/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 340/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 341/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 342/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 343/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 344/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 345/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 346/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 347/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 348/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 349/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 350/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 351/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 352/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 353/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 354/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 355/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 356/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 357/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 358/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 359/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 360/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 361/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 362/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 363/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 364/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 365/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 366/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 367/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 368/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 369/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 370/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 371/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 372/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 373/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 374/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 375/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 376/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 377/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 378/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 379/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 380/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 381/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 382/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 383/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 384/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 385/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 386/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 387/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 388/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 389/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 390/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 391/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 392/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 393/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 394/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 395/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 396/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 397/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 398/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 399/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 400/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 401/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 402/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 403/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 404/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 405/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 406/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 407/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 408/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 409/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 410/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 411/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 412/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 413/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 414/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 415/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 416/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 417/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 418/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 419/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 420/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 421/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 422/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 423/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 424/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 425/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 426/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 427/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 428/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 429/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 430/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 431/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 432/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 433/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 434/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 435/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 436/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 437/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 438/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 439/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 440/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 441/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 442/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 443/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 444/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 445/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 446/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 447/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 448/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 449/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 450/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 451/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 452/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 453/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 454/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 455/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 456/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 457/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 458/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 459/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 460/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 461/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 462/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 463/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 464/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 465/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 466/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 467/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 468/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 469/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 470/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 471/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 472/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 473/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 474/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 475/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 476/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 477/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 478/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 479/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 480/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 481/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 482/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 483/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 484/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 485/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 486/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 487/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 488/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 489/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 490/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 491/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 492/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 493/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 494/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 495/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 496/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 497/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 498/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 499/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 500/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 501/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 502/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 503/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 504/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 505/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 506/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 507/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 508/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 509/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 510/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 511/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 512/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 513/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 514/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 515/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 516/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 517/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 518/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 519/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 520/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 521/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 522/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 523/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 524/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 525/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 526/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 527/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 528/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 529/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 530/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 531/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 532/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 533/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 534/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 535/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 536/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 537/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 538/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 539/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 540/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 541/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 542/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 543/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 544/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 545/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 546/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 547/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 548/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 549/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 550/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 551/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 552/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 553/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 554/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 555/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 556/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 557/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 558/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 559/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 560/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 561/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 562/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 563/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 564/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 565/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 566/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 567/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 568/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 569/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 570/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 571/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 572/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 573/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 574/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 575/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 576/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 577/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 578/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 579/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 580/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 581/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 582/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 583/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 584/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 585/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 586/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 587/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 588/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 589/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 590/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 591/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 592/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 593/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 594/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 595/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 596/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 597/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 598/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 599/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 600/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 601/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 602/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 603/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 604/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 605/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 606/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 607/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 608/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 609/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 610/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 611/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 612/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 613/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 614/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 615/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 616/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 617/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 618/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 619/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 620/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 621/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 622/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 623/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 624/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 625/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 626/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 627/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 628/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 629/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 630/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 631/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 632/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 633/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 634/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 635/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 636/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 637/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 638/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 639/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 640/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 641/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 642/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 643/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 644/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 645/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 646/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 647/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 648/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 649/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 650/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 651/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 652/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 653/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 654/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 655/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 656/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 657/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 658/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 659/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 660/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 661/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 662/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 663/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 664/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 665/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 666/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 667/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 668/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 669/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 670/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 671/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 672/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 673/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 674/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 675/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 676/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 677/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 678/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 679/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 680/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 681/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 682/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 683/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 684/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 685/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 686/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 687/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 688/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 689/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 690/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 691/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 692/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 693/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 694/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 695/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 696/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 697/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 698/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 699/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 700/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 701/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 702/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 703/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 704/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 705/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 706/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 707/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 708/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 709/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 710/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 711/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 712/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 713/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 714/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 715/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 716/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 717/2000\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 718/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 719/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 720/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 721/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 722/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 723/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 724/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 725/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 726/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 727/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 728/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 729/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 730/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 731/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 732/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 733/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 734/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 735/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 736/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 737/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 738/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 739/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 740/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 741/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 742/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 743/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 744/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 745/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 746/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 747/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 748/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 749/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 750/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 751/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 752/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 753/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 754/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 755/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 756/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 757/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 758/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 759/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 760/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 761/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 762/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 763/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 764/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 765/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 766/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 767/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 768/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 769/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 770/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 771/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 772/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 773/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 774/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 775/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 776/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 777/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 778/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 779/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 780/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 781/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 782/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 783/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 784/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 785/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 786/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 787/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 788/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 789/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 790/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 791/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 792/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 793/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 794/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 795/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 796/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 797/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 798/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 799/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 800/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 801/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 802/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 803/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 804/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 805/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 806/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 807/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 808/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 809/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 810/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 811/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 812/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 813/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 814/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 815/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 816/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 817/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 818/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 819/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 820/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 821/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 822/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 823/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 824/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 825/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 826/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 827/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 828/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 829/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 830/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 831/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 832/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 833/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 834/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 835/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 836/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 837/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 838/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 839/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 840/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 841/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 842/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 843/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 844/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 845/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 846/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 847/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 848/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 849/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 850/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 851/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 852/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 853/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 854/2000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 855/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 856/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 857/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 858/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 859/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 860/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 861/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 862/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 863/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 864/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 865/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 866/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 867/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 868/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 869/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 870/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 871/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 872/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 873/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 874/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 875/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 876/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 877/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 878/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 879/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 880/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 881/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 882/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 883/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 884/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 885/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 886/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 887/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 888/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 889/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 890/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 891/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 892/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 893/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 894/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 895/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 896/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 897/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 898/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 899/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 900/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 901/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 902/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 903/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 904/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 905/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 906/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 907/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 908/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 909/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 910/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 911/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 912/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 913/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 914/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 915/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 916/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 917/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 918/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 919/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 920/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 921/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 922/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 923/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 924/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 925/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 926/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 927/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 928/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 929/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 930/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 931/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 932/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 933/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 934/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 935/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 936/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 937/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 938/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 939/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 940/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 941/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 942/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 943/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 944/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 945/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 946/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 947/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 948/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 949/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 950/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 951/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 952/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 953/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 954/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 955/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 956/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 957/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 958/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 959/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 960/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 961/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 962/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 963/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 964/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 965/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 966/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 967/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 968/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 969/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 970/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 971/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 972/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 973/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 974/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 975/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 976/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 977/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 978/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 979/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 980/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 981/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 982/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 983/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 984/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 985/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 986/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 987/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 988/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 989/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 990/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 991/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 992/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 993/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 994/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 995/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 996/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 997/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 998/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 999/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1000/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1001/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1002/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1003/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1004/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1005/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1006/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1007/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1008/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1009/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1010/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1011/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1012/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1013/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1014/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1015/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1016/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1017/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1018/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1019/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1020/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1021/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1022/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1023/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1024/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1025/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1026/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1027/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1028/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1029/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1030/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1031/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1032/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1033/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1034/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1035/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1036/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1037/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1038/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1039/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1040/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1041/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1042/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1043/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1044/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1045/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1046/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1047/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1048/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1049/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1050/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1051/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1052/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1053/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1054/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1055/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1056/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1057/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1058/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1059/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1060/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1061/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1062/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1063/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1064/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1065/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1066/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1067/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1068/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1069/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1070/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1071/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1072/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 1073/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1074/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1075/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1076/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1077/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1078/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1079/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1080/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1081/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1082/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1083/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1084/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1085/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1086/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1087/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1088/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1089/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1090/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1091/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1092/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1093/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1094/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1095/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1096/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1097/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1098/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1099/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1100/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1101/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1102/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1103/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1104/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1105/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1106/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1107/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1108/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1109/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1110/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1111/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1112/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1113/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1114/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1115/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1116/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1117/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1118/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1119/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1120/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1121/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1122/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1123/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1124/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1125/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1126/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1127/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1128/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1129/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1130/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1131/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1132/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1133/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1134/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1135/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1136/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1137/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1138/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1139/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1140/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1141/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1142/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1143/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1144/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1145/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1146/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1147/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1148/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1149/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1150/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1151/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1152/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1153/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1154/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1155/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1156/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1157/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1158/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1159/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1160/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1161/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1162/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1163/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1164/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1165/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1166/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1167/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1168/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1169/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1170/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1171/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1172/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1173/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1174/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1175/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1176/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1177/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1178/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1179/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1180/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1181/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1182/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1183/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1184/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1185/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1186/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1187/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1188/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1189/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1190/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1191/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1192/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1193/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1194/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1195/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1196/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1197/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1198/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1199/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1200/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1201/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1202/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1203/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1204/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1205/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1206/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1207/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1208/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1209/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1210/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1211/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1212/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1213/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1214/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1215/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1216/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1217/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1218/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1219/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1220/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1221/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1222/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1223/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1224/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1225/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1226/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1227/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1228/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1229/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1230/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1231/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1232/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1233/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1234/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1235/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1236/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1237/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1238/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1239/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1240/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1241/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1242/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1243/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1244/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1245/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1246/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1247/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1248/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1249/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1250/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1251/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1252/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1253/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1254/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1255/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1256/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1257/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1258/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1259/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1260/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1261/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1262/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1263/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1264/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1265/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1266/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1267/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1268/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1269/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1270/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1271/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1272/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1273/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1274/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1275/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1276/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1277/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1278/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1279/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1280/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1281/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1282/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1283/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1284/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1285/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1286/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1287/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1288/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1289/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1290/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1291/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1292/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1293/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1294/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1295/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1296/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1297/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1298/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1299/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1300/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1301/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1302/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1303/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1304/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1305/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1306/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1307/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1308/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1309/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1310/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1311/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1312/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1313/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1314/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1315/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1316/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1317/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1318/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1319/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1320/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1321/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1322/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1323/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1324/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1325/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1326/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1327/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1328/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1329/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1330/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1331/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1332/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1333/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1334/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1335/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1336/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1337/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1338/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1339/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1340/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1341/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1342/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1343/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1344/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1345/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1346/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1347/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1348/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1349/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1350/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1351/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1352/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1353/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1354/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1355/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1356/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1357/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1358/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1359/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1360/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1361/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1362/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1363/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1364/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1365/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1366/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1367/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1368/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1369/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1370/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1371/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1372/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1373/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1374/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1375/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1376/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1377/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1378/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1379/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1380/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1381/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1382/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1383/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1384/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1385/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1386/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1387/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1388/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1389/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1390/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1391/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1392/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1393/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1394/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1395/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1396/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1397/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1398/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1399/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1400/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1401/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1402/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1403/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1404/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1405/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1406/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1407/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1408/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1409/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1410/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1411/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1412/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1413/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1414/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1415/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1416/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1417/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1418/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1419/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1420/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1421/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1422/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1423/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1424/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1425/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1426/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1427/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1428/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1429/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1430/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1431/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1432/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1433/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1434/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1435/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1436/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1437/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1438/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1439/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1440/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1441/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1442/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1443/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1444/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1445/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1446/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1447/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1448/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1449/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1450/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1451/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1452/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1453/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1454/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1455/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1456/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1457/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1458/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1459/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1460/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1461/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1462/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1463/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1464/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1465/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1466/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1467/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1468/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1469/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1470/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1471/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1472/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1473/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1474/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1475/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1476/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1477/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1478/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1479/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1480/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1481/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1482/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1483/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1484/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1485/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1486/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1487/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1488/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1489/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1490/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1491/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1492/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1493/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1494/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1495/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1496/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1497/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1498/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1499/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1500/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1501/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1502/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1503/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1504/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1505/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1506/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1507/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1508/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1509/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1510/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1511/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1512/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1513/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1514/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1515/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1516/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1517/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1518/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1519/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1520/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1521/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1522/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1523/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1524/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1525/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1526/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1527/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1528/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1529/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1530/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1531/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1532/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1533/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1534/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1535/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1536/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1537/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1538/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1539/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1540/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1541/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1542/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1543/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1544/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1545/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1546/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1547/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1548/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1549/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1550/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1551/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1552/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1553/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1554/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1555/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1556/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1557/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1558/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1559/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1560/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1561/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1562/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1563/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1564/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1565/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1566/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1567/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1568/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1569/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1570/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1571/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1572/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1573/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1574/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1575/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1576/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1577/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1578/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1579/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1580/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1581/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1582/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1583/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1584/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1585/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1586/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1587/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1588/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1589/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1590/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1591/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1592/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1593/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1594/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1595/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1596/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1597/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1598/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1599/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1600/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1601/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1602/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1603/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1604/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1605/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1606/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1607/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1608/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1609/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1610/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1611/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1612/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1613/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1614/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1615/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1616/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1617/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1618/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1619/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1620/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1621/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1622/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1623/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1624/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1625/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1626/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1627/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1628/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1629/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1630/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1631/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1632/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1633/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1634/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1635/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1636/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1637/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1638/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1639/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1640/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1641/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1642/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1643/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1644/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1645/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1646/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1647/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1648/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1649/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1650/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1651/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1652/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1653/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1654/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1655/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1656/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1657/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1658/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1659/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1660/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1661/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1662/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1663/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1664/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1665/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1666/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1667/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1668/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1669/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1670/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1671/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1672/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1673/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1674/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1675/2000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1676/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1677/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1678/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1679/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1680/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1681/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1682/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1683/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1684/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1685/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1686/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1687/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1688/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1689/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1690/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1691/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1692/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1693/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1694/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1695/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1696/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1697/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1698/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1699/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1700/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1701/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1702/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1703/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1704/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1705/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1706/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1707/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1708/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1709/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1710/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1711/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1712/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1713/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1714/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1715/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1716/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1717/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1718/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1719/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1720/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1721/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1722/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1723/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1724/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1725/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1726/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1727/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1728/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1729/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1730/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1731/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1732/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1733/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1734/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1735/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1736/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1737/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1738/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1739/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1740/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1741/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1742/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1743/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1744/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1745/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1746/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1747/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1748/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1749/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1750/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1751/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1752/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1753/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1754/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1755/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1756/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1757/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1758/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1759/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1760/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1761/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1762/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1763/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1764/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1765/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1766/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1767/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1768/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1769/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1770/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1771/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1772/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1773/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1774/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1775/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1776/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1777/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1778/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1779/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1780/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1781/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1782/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1783/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1784/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1785/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1786/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1787/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1788/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1789/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1790/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1791/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1792/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1793/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1794/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1795/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1796/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1797/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1798/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1799/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1800/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1801/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1802/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1803/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1804/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1805/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1806/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1807/2000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1808/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1809/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1810/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1811/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1812/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1813/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1814/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1815/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1816/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1817/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1818/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1819/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1820/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1821/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1822/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1823/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1824/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1825/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1826/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1827/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1828/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1829/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1830/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1831/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1832/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1833/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1834/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1835/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1836/2000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1837/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1838/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1839/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1840/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1841/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1842/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1843/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1844/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1845/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1846/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1847/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1848/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1849/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1850/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1851/2000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1852/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1853/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1854/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1855/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1856/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1857/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1858/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1859/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1860/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1861/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1862/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1863/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1864/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1865/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1866/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1867/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1868/2000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1869/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1870/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1871/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1872/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1873/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1874/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1875/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1876/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1877/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1878/2000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1879/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1880/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1881/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1882/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1883/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1884/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1885/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1886/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1887/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1888/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1889/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1890/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1891/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1892/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1893/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1894/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1895/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1896/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1897/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1898/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1899/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1900/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1901/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1902/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1903/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1904/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1905/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1906/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1907/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1908/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1909/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1910/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1911/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1912/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1913/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1914/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1915/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1916/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1917/2000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1918/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1919/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1920/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1921/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1922/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1923/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1924/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1925/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1926/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1927/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1928/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1929/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1930/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1931/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1932/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1933/2000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1934/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1935/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1936/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1937/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1938/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1939/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1940/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1941/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1942/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1943/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1944/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1945/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1946/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1947/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1948/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1949/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1950/2000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1951/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1952/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1953/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1954/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1955/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1956/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1957/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1958/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1959/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1960/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1961/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1962/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1963/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1964/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1965/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1966/2000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1967/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1968/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1969/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1970/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1971/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1972/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1973/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1974/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1975/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1976/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1977/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1978/2000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1979/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1980/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1981/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1982/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1983/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1984/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1985/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1986/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1987/2000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1988/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1989/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1990/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1991/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1992/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1993/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1994/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1995/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1996/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1997/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1998/2000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 1999/2000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 2000/2000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "h2 = model2.fit(X_XOR, y_XOR, batch_size=4, epochs=2000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jzzaT-SKwklk"
      },
      "source": [
        "# MLP 만들기"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 퍼셉트론 2개로 신경망 구성하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aYQySnFFwrX7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 2         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 5\n",
            "Trainable params: 5\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Dense(units=1, input_dim=2))\n",
        "model3.add(Activation(\"sigmoid\"))\n",
        "\n",
        "# 2번째 층 부터는 input_dim을 설정하지 않아도 자동으로 인식\n",
        "model3.add(Dense(units=1))\n",
        "model3.add(Activation(\"sigmoid\"))\n",
        "\n",
        "model3.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PZuG4WqmyE_b"
      },
      "source": [
        "### 퍼셉트론 5개로 신경망 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "clfK5b6N0-XZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 4)                 12        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 17\n",
            "Trainable params: 17\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model5 = Sequential()\n",
        "\n",
        "model5.add(Dense(units=4, input_dim=2, activation='sigmoid'))\n",
        "model5.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model5.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "o69YGrv61qQp"
      },
      "outputs": [],
      "source": [
        "model5.compile(loss=\"binary_crossentropy\",\n",
        "               optimizer=\"adam\",\n",
        "               metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9Mo9M_GT1qXy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-13 23:51:08.101633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 426ms/step - loss: 0.7779 - accuracy: 0.5000\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7772 - accuracy: 0.5000\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7765 - accuracy: 0.5000\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7757 - accuracy: 0.5000\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7750 - accuracy: 0.5000\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7743 - accuracy: 0.5000\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7736 - accuracy: 0.5000\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7729 - accuracy: 0.5000\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7722 - accuracy: 0.5000\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7715 - accuracy: 0.5000\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7708 - accuracy: 0.5000\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7701 - accuracy: 0.5000\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7694 - accuracy: 0.5000\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7687 - accuracy: 0.5000\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7680 - accuracy: 0.5000\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7673 - accuracy: 0.5000\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7667 - accuracy: 0.5000\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7660 - accuracy: 0.5000\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7653 - accuracy: 0.5000\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7647 - accuracy: 0.5000\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7640 - accuracy: 0.5000\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7634 - accuracy: 0.5000\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7627 - accuracy: 0.5000\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7621 - accuracy: 0.5000\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7614 - accuracy: 0.5000\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7608 - accuracy: 0.5000\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7602 - accuracy: 0.5000\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7595 - accuracy: 0.5000\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7589 - accuracy: 0.5000\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7583 - accuracy: 0.5000\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7577 - accuracy: 0.5000\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7571 - accuracy: 0.5000\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7565 - accuracy: 0.5000\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7559 - accuracy: 0.5000\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7553 - accuracy: 0.5000\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7547 - accuracy: 0.5000\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7541 - accuracy: 0.5000\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7535 - accuracy: 0.5000\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7530 - accuracy: 0.5000\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7524 - accuracy: 0.5000\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7518 - accuracy: 0.5000\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7513 - accuracy: 0.5000\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7507 - accuracy: 0.5000\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7501 - accuracy: 0.5000\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7496 - accuracy: 0.5000\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7491 - accuracy: 0.5000\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7485 - accuracy: 0.5000\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7480 - accuracy: 0.5000\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7475 - accuracy: 0.5000\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7469 - accuracy: 0.5000\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7464 - accuracy: 0.5000\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7459 - accuracy: 0.5000\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7454 - accuracy: 0.5000\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7449 - accuracy: 0.5000\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7444 - accuracy: 0.5000\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7439 - accuracy: 0.5000\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7434 - accuracy: 0.5000\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7429 - accuracy: 0.5000\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7424 - accuracy: 0.5000\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7419 - accuracy: 0.5000\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7414 - accuracy: 0.5000\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7410 - accuracy: 0.5000\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7405 - accuracy: 0.5000\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7400 - accuracy: 0.5000\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7396 - accuracy: 0.5000\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7391 - accuracy: 0.5000\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7387 - accuracy: 0.5000\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7382 - accuracy: 0.5000\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7378 - accuracy: 0.5000\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7373 - accuracy: 0.5000\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7369 - accuracy: 0.5000\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7365 - accuracy: 0.5000\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7361 - accuracy: 0.5000\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7356 - accuracy: 0.5000\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7352 - accuracy: 0.5000\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7348 - accuracy: 0.5000\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7344 - accuracy: 0.5000\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7340 - accuracy: 0.5000\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7336 - accuracy: 0.5000\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7332 - accuracy: 0.5000\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7328 - accuracy: 0.5000\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7324 - accuracy: 0.5000\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7320 - accuracy: 0.5000\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7316 - accuracy: 0.5000\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7312 - accuracy: 0.5000\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7309 - accuracy: 0.5000\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7305 - accuracy: 0.5000\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7301 - accuracy: 0.5000\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7298 - accuracy: 0.5000\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7294 - accuracy: 0.5000\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7290 - accuracy: 0.5000\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7287 - accuracy: 0.5000\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7283 - accuracy: 0.5000\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7280 - accuracy: 0.5000\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7277 - accuracy: 0.5000\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7273 - accuracy: 0.5000\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7270 - accuracy: 0.5000\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7266 - accuracy: 0.5000\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7263 - accuracy: 0.5000\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7260 - accuracy: 0.5000\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7257 - accuracy: 0.5000\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7253 - accuracy: 0.5000\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7250 - accuracy: 0.5000\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7247 - accuracy: 0.5000\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7244 - accuracy: 0.5000\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7241 - accuracy: 0.5000\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7238 - accuracy: 0.5000\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7235 - accuracy: 0.5000\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7232 - accuracy: 0.5000\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7229 - accuracy: 0.5000\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7226 - accuracy: 0.5000\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7223 - accuracy: 0.5000\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7220 - accuracy: 0.5000\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7218 - accuracy: 0.5000\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7215 - accuracy: 0.5000\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7212 - accuracy: 0.5000\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7209 - accuracy: 0.5000\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7207 - accuracy: 0.5000\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7204 - accuracy: 0.5000\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7201 - accuracy: 0.5000\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7199 - accuracy: 0.5000\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7196 - accuracy: 0.5000\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7194 - accuracy: 0.5000\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7191 - accuracy: 0.5000\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7189 - accuracy: 0.5000\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7186 - accuracy: 0.5000\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7184 - accuracy: 0.5000\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7181 - accuracy: 0.5000\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7179 - accuracy: 0.5000\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7177 - accuracy: 0.5000\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7174 - accuracy: 0.5000\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7172 - accuracy: 0.5000\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7170 - accuracy: 0.5000\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7168 - accuracy: 0.5000\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7165 - accuracy: 0.5000\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7163 - accuracy: 0.5000\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7161 - accuracy: 0.5000\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7159 - accuracy: 0.5000\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7157 - accuracy: 0.5000\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7155 - accuracy: 0.5000\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7153 - accuracy: 0.5000\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7150 - accuracy: 0.7500\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7148 - accuracy: 0.7500\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7146 - accuracy: 0.7500\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7144 - accuracy: 0.7500\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7143 - accuracy: 0.7500\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7141 - accuracy: 0.7500\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7139 - accuracy: 0.7500\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7137 - accuracy: 0.7500\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7135 - accuracy: 0.7500\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7133 - accuracy: 0.7500\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7131 - accuracy: 0.7500\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7129 - accuracy: 0.7500\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7128 - accuracy: 0.7500\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7126 - accuracy: 0.7500\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7124 - accuracy: 0.7500\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7122 - accuracy: 0.7500\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7121 - accuracy: 0.7500\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7119 - accuracy: 0.7500\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7117 - accuracy: 0.7500\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7116 - accuracy: 0.7500\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7114 - accuracy: 0.7500\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7113 - accuracy: 0.7500\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7111 - accuracy: 0.7500\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7109 - accuracy: 0.7500\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7108 - accuracy: 0.7500\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7106 - accuracy: 0.7500\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7105 - accuracy: 0.7500\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7103 - accuracy: 0.7500\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7102 - accuracy: 0.7500\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7100 - accuracy: 0.7500\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7099 - accuracy: 0.7500\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7098 - accuracy: 0.7500\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7096 - accuracy: 0.7500\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7095 - accuracy: 0.7500\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7093 - accuracy: 0.7500\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7092 - accuracy: 0.7500\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7091 - accuracy: 0.7500\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7089 - accuracy: 0.7500\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7088 - accuracy: 0.7500\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7087 - accuracy: 0.7500\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7085 - accuracy: 0.7500\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7084 - accuracy: 0.7500\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7083 - accuracy: 0.7500\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7082 - accuracy: 0.7500\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7081 - accuracy: 0.7500\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7079 - accuracy: 0.7500\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7078 - accuracy: 0.7500\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7077 - accuracy: 0.7500\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7076 - accuracy: 0.7500\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7075 - accuracy: 0.7500\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7074 - accuracy: 0.7500\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7072 - accuracy: 0.7500\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7071 - accuracy: 0.7500\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7070 - accuracy: 0.7500\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7069 - accuracy: 0.7500\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7068 - accuracy: 0.7500\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7067 - accuracy: 0.7500\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7066 - accuracy: 0.7500\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7065 - accuracy: 0.7500\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7064 - accuracy: 0.7500\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7063 - accuracy: 0.7500\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7062 - accuracy: 0.7500\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7061 - accuracy: 0.7500\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7060 - accuracy: 0.7500\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7059 - accuracy: 0.7500\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7058 - accuracy: 0.7500\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7057 - accuracy: 0.7500\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7056 - accuracy: 0.7500\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7055 - accuracy: 0.7500\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7054 - accuracy: 0.7500\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7054 - accuracy: 0.7500\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7053 - accuracy: 0.7500\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7052 - accuracy: 0.7500\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7051 - accuracy: 0.7500\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7050 - accuracy: 0.7500\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7049 - accuracy: 0.7500\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7048 - accuracy: 0.7500\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7048 - accuracy: 0.7500\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7047 - accuracy: 0.7500\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7046 - accuracy: 0.7500\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7045 - accuracy: 0.7500\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7044 - accuracy: 0.7500\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7044 - accuracy: 0.7500\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7043 - accuracy: 0.7500\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7042 - accuracy: 0.7500\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7041 - accuracy: 0.7500\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7041 - accuracy: 0.7500\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7040 - accuracy: 0.7500\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7039 - accuracy: 0.7500\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7039 - accuracy: 0.7500\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7038 - accuracy: 0.7500\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7037 - accuracy: 0.7500\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7036 - accuracy: 0.7500\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7036 - accuracy: 0.7500\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7035 - accuracy: 0.7500\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7034 - accuracy: 0.7500\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7034 - accuracy: 0.7500\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7033 - accuracy: 0.7500\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7033 - accuracy: 0.7500\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7032 - accuracy: 0.7500\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7031 - accuracy: 0.7500\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7031 - accuracy: 0.7500\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7030 - accuracy: 0.7500\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7029 - accuracy: 0.7500\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7029 - accuracy: 0.7500\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7028 - accuracy: 0.7500\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7028 - accuracy: 0.7500\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7027 - accuracy: 0.7500\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7026 - accuracy: 0.7500\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7026 - accuracy: 0.7500\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7025 - accuracy: 0.7500\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7025 - accuracy: 0.7500\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7024 - accuracy: 0.7500\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7024 - accuracy: 0.7500\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7023 - accuracy: 0.7500\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.7023 - accuracy: 0.7500\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7022 - accuracy: 0.7500\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7022 - accuracy: 0.7500\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7021 - accuracy: 0.7500\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7020 - accuracy: 0.7500\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7020 - accuracy: 0.7500\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7019 - accuracy: 0.7500\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7019 - accuracy: 0.7500\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7018 - accuracy: 0.7500\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7018 - accuracy: 0.7500\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7018 - accuracy: 0.7500\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7017 - accuracy: 0.7500\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7017 - accuracy: 0.7500\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7016 - accuracy: 0.7500\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7016 - accuracy: 0.7500\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7015 - accuracy: 0.7500\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7015 - accuracy: 0.7500\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7014 - accuracy: 0.7500\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7014 - accuracy: 0.7500\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7013 - accuracy: 0.7500\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7013 - accuracy: 0.7500\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7012 - accuracy: 0.7500\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7012 - accuracy: 0.7500\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7012 - accuracy: 0.7500\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7011 - accuracy: 0.7500\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7011 - accuracy: 0.7500\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7010 - accuracy: 0.7500\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7010 - accuracy: 0.7500\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7010 - accuracy: 0.7500\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.7500\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7009 - accuracy: 0.7500\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7008 - accuracy: 0.7500\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7008 - accuracy: 0.7500\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7008 - accuracy: 0.7500\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7007 - accuracy: 0.7500\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7007 - accuracy: 0.7500\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7006 - accuracy: 0.7500\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7006 - accuracy: 0.7500\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7006 - accuracy: 0.7500\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7005 - accuracy: 0.7500\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7005 - accuracy: 0.7500\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7005 - accuracy: 0.7500\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7004 - accuracy: 0.7500\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7004 - accuracy: 0.7500\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.7003 - accuracy: 0.7500\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7003 - accuracy: 0.7500\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7003 - accuracy: 0.7500\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7002 - accuracy: 0.7500\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7002 - accuracy: 0.7500\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7002 - accuracy: 0.7500\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7001 - accuracy: 0.7500\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7001 - accuracy: 0.7500\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7001 - accuracy: 0.7500\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7000 - accuracy: 0.7500\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7000 - accuracy: 0.7500\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7000 - accuracy: 0.7500\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6999 - accuracy: 0.7500\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6999 - accuracy: 0.7500\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6999 - accuracy: 0.7500\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6998 - accuracy: 0.7500\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6998 - accuracy: 0.7500\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6998 - accuracy: 0.7500\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6997 - accuracy: 0.7500\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6997 - accuracy: 0.7500\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6997 - accuracy: 0.7500\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6996 - accuracy: 0.7500\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6996 - accuracy: 0.7500\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6996 - accuracy: 0.7500\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6996 - accuracy: 0.7500\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.7500\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.7500\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6995 - accuracy: 0.7500\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6994 - accuracy: 0.7500\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6994 - accuracy: 0.7500\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6994 - accuracy: 0.7500\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6994 - accuracy: 0.7500\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.7500\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.7500\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6993 - accuracy: 0.7500\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6992 - accuracy: 0.7500\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.7500\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.7500\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6992 - accuracy: 0.7500\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6991 - accuracy: 0.7500\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6991 - accuracy: 0.7500\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6991 - accuracy: 0.7500\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.7500\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.7500\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.7500\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.7500\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6989 - accuracy: 0.7500\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6989 - accuracy: 0.7500\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6989 - accuracy: 0.7500\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6989 - accuracy: 0.7500\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.7500\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6988 - accuracy: 0.7500\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6988 - accuracy: 0.7500\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.7500\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6987 - accuracy: 0.7500\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6987 - accuracy: 0.7500\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6987 - accuracy: 0.7500\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6987 - accuracy: 0.7500\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.7500\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.7500\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.7500\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6986 - accuracy: 0.7500\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6985 - accuracy: 0.7500\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6985 - accuracy: 0.7500\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6985 - accuracy: 0.7500\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6985 - accuracy: 0.7500\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6984 - accuracy: 0.7500\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6984 - accuracy: 0.7500\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6984 - accuracy: 0.7500\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6984 - accuracy: 0.7500\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6983 - accuracy: 0.7500\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6983 - accuracy: 0.7500\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6983 - accuracy: 0.7500\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6983 - accuracy: 0.7500\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6982 - accuracy: 0.7500\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6982 - accuracy: 0.7500\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6982 - accuracy: 0.7500\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6982 - accuracy: 0.7500\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6982 - accuracy: 0.7500\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6981 - accuracy: 0.7500\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6981 - accuracy: 0.7500\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6981 - accuracy: 0.7500\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6981 - accuracy: 0.7500\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6980 - accuracy: 0.7500\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6980 - accuracy: 0.7500\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6980 - accuracy: 0.7500\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6980 - accuracy: 0.7500\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6980 - accuracy: 0.5000\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.5000\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6975 - accuracy: 0.5000\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.5000\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6973 - accuracy: 0.5000\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.5000\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.5000\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6965 - accuracy: 0.5000\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6962 - accuracy: 0.5000\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6944 - accuracy: 0.5000\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5000\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5000\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5000\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6929 - accuracy: 0.5000\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5000\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5000\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.5000\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.5000\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.5000\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.5000\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6923 - accuracy: 0.5000\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6923 - accuracy: 0.5000\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6923 - accuracy: 0.5000\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.5000\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6919 - accuracy: 0.5000\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6918 - accuracy: 0.5000\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.5000\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.5000\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.5000\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.5000\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6917 - accuracy: 0.5000\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6915 - accuracy: 0.5000\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6915 - accuracy: 0.5000\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6915 - accuracy: 0.5000\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6915 - accuracy: 0.5000\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6915 - accuracy: 0.5000\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6915 - accuracy: 0.5000\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6914 - accuracy: 0.5000\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5000\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6914 - accuracy: 0.5000\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5000\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6914 - accuracy: 0.5000\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6914 - accuracy: 0.5000\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6913 - accuracy: 0.5000\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.5000\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.5000\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6913 - accuracy: 0.5000\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.5000\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6912 - accuracy: 0.5000\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.5000\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.5000\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6912 - accuracy: 0.5000\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6912 - accuracy: 0.5000\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6912 - accuracy: 0.5000\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.5000\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.5000\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6910 - accuracy: 0.5000\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6910 - accuracy: 0.5000\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6910 - accuracy: 0.5000\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6910 - accuracy: 0.5000\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5000\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5000\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5000\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5000\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6909 - accuracy: 0.5000\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6909 - accuracy: 0.5000\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.5000\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.5000\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6908 - accuracy: 0.5000\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6908 - accuracy: 0.5000\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6908 - accuracy: 0.5000\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.5000\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.5000\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.5000\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.5000\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6907 - accuracy: 0.5000\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6907 - accuracy: 0.5000\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6906 - accuracy: 0.5000\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.5000\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.5000\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6906 - accuracy: 0.5000\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6906 - accuracy: 0.5000\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.5000\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6904 - accuracy: 0.5000\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5000\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5000\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.5000\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.5000\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.5000\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6903 - accuracy: 0.5000\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.5000\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.5000\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.5000\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6902 - accuracy: 0.5000\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6902 - accuracy: 0.5000\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6902 - accuracy: 0.5000\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6902 - accuracy: 0.5000\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6902 - accuracy: 0.5000\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.5000\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6901 - accuracy: 0.5000\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6901 - accuracy: 0.5000\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6901 - accuracy: 0.5000\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6901 - accuracy: 0.5000\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6900 - accuracy: 0.5000\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6900 - accuracy: 0.5000\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6900 - accuracy: 0.5000\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6900 - accuracy: 0.5000\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6900 - accuracy: 0.5000\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5000\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.5000\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.5000\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5000\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5000\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.5000\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.5000\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6897 - accuracy: 0.5000\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.5000\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6897 - accuracy: 0.5000\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6897 - accuracy: 0.5000\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6897 - accuracy: 0.5000\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6896 - accuracy: 0.5000\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6896 - accuracy: 0.5000\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.5000\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6896 - accuracy: 0.5000\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6896 - accuracy: 0.5000\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6895 - accuracy: 0.5000\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6895 - accuracy: 0.5000\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5000\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6895 - accuracy: 0.5000\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6895 - accuracy: 0.5000\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6894 - accuracy: 0.5000\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6894 - accuracy: 0.5000\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6894 - accuracy: 0.5000\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6894 - accuracy: 0.5000\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6894 - accuracy: 0.5000\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6893 - accuracy: 0.5000\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6893 - accuracy: 0.5000\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6893 - accuracy: 0.5000\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5000\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6893 - accuracy: 0.5000\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5000\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6892 - accuracy: 0.5000\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6892 - accuracy: 0.5000\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6892 - accuracy: 0.5000\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6892 - accuracy: 0.5000\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6891 - accuracy: 0.5000\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6891 - accuracy: 0.5000\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6891 - accuracy: 0.5000\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6891 - accuracy: 0.5000\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6891 - accuracy: 0.5000\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6890 - accuracy: 0.5000\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5000\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5000\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6890 - accuracy: 0.5000\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.5000\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.5000\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.5000\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6889 - accuracy: 0.5000\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.5000\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6889 - accuracy: 0.5000\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6888 - accuracy: 0.5000\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6888 - accuracy: 0.5000\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6888 - accuracy: 0.5000\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6888 - accuracy: 0.5000\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6887 - accuracy: 0.5000\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6887 - accuracy: 0.5000\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6887 - accuracy: 0.5000\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6887 - accuracy: 0.5000\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6887 - accuracy: 0.5000\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6886 - accuracy: 0.5000\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6886 - accuracy: 0.5000\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6886 - accuracy: 0.5000\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6886 - accuracy: 0.5000\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6886 - accuracy: 0.5000\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6885 - accuracy: 0.5000\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6885 - accuracy: 0.5000\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6885 - accuracy: 0.5000\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6885 - accuracy: 0.5000\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6885 - accuracy: 0.5000\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6884 - accuracy: 0.5000\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6884 - accuracy: 0.5000\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6884 - accuracy: 0.5000\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6884 - accuracy: 0.5000\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6883 - accuracy: 0.5000\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6883 - accuracy: 0.5000\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6883 - accuracy: 0.5000\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6883 - accuracy: 0.5000\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6883 - accuracy: 0.5000\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6882 - accuracy: 0.5000\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6882 - accuracy: 0.5000\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6882 - accuracy: 0.5000\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6882 - accuracy: 0.5000\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6882 - accuracy: 0.5000\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.5000\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6881 - accuracy: 0.5000\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6881 - accuracy: 0.5000\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6881 - accuracy: 0.5000\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6880 - accuracy: 0.5000\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6880 - accuracy: 0.5000\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6880 - accuracy: 0.5000\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6880 - accuracy: 0.5000\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6880 - accuracy: 0.5000\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6879 - accuracy: 0.5000\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.5000\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6879 - accuracy: 0.5000\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6879 - accuracy: 0.5000\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6878 - accuracy: 0.5000\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6878 - accuracy: 0.5000\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6878 - accuracy: 0.5000\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6878 - accuracy: 0.5000\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6878 - accuracy: 0.5000\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6877 - accuracy: 0.5000\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.5000\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6877 - accuracy: 0.5000\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6877 - accuracy: 0.5000\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6876 - accuracy: 0.5000\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.5000\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.5000\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6876 - accuracy: 0.5000\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6875 - accuracy: 0.5000\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6875 - accuracy: 0.5000\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6875 - accuracy: 0.5000\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6875 - accuracy: 0.5000\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6875 - accuracy: 0.5000\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6874 - accuracy: 0.5000\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6874 - accuracy: 0.5000\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6874 - accuracy: 0.5000\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6874 - accuracy: 0.5000\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6873 - accuracy: 0.5000\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6873 - accuracy: 0.5000\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6873 - accuracy: 0.5000\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6873 - accuracy: 0.5000\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6872 - accuracy: 0.5000\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5000\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.5000\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6872 - accuracy: 0.5000\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.5000\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6871 - accuracy: 0.5000\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5000\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5000\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6871 - accuracy: 0.5000\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.5000\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.5000\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6870 - accuracy: 0.5000\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6870 - accuracy: 0.5000\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6869 - accuracy: 0.5000\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6869 - accuracy: 0.5000\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.5000\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6869 - accuracy: 0.5000\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6868 - accuracy: 0.5000\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6868 - accuracy: 0.5000\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6868 - accuracy: 0.5000\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6868 - accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "h2 = model5.fit(X_XOR, y_XOR, batch_size=4, epochs=1000)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bGZVmBJX_mTl"
      },
      "source": [
        "### 6개 퍼셉트론이 3층으로 구성된 신경 설계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4CSgWT0wrh0",
        "outputId": "c7d1c553-3129-4022-a627-f697d37898ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 3)                 9         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2)                 8         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model6 = Sequential()\n",
        "# 입력층\n",
        "model6.add(Dense(3, input_dim=2 , activation=\"sigmoid\"))  #unit 퍼셉트론 수만 정해주면 된다. 선 기준 x 동그라미 기준 o \n",
        "# 은닉층 -> 특성 추출 층\n",
        "model6.add(Dense(2, activation=\"sigmoid\"))\n",
        "# 출력층 -> 분류인 경우 라벨값의 수만큼 유닛 설정 (1,0 이진으로) (단순히 맞다 아니다면 1개)\n",
        "model6.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model6.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ngQZtv-3DPMa"
      },
      "source": [
        "## 신경망에 층을 쌓는 방법들\n",
        "- 인코딩 방식 : 퍼셉트론을 점점 줄여가는 방식(특성 추출)\n",
        "- 디코딩 방식 : 퍼셉트론을 점점 늘려가는 방식\n",
        "- 리니어 방식 : 퍼셉트론의 수가 일정한 방식"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 배치하는 방식\n",
        "- 인코딩 -> 디코딩\n",
        "- 디코딩 -> 인코딩\n",
        "- 인코딩 -> 리니어\n",
        "- 디코딩 -> 리니어\n",
        "- 리니어 -> 인코딩\n",
        "- 리니어 -> 디코딩"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4i_DPvjEHGfa"
      },
      "source": [
        "# (요약!) 텐서플로우 신경망 구성"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "fDtSFm0mFTlZ"
      },
      "source": [
        "## 모델 구성\n",
        "     modelName.add(Dense(units= , input_dim= , activation= ))  \n",
        "- Sequential() : 신경망을 쌓는 토대 (신경망 생성) \n",
        "- Dense() : 실제 신경망 층을 설정하는 기능 (신경망에 퍼셉트론 층 추가)\n",
        "  - units : 현재 층에 존재하는 퍼셉트론의 수 (출력 수)\n",
        "  - input_dim : 입력 차수 (입력되는 feature의 수)\n",
        "- Activation() : 활성화 함수를 설정 (시그모이드, 렐루 등) \n",
        "- add() : Dense나 Activation 등을 신경망에 추가 \n",
        "- Optimizers : 최적화 함수 (경사하강법 종류)\n",
        "#### 종류(사용되는 층)\n",
        "- sigmoid(입력, 은닉, 출력)\n",
        "- tanh(입력, 은닉)\n",
        "- relu(입력, 은닉) \n",
        "- softmax(출력)\n",
        "#### 유형별 최적화\n",
        "- 회귀 -> 1 Activation -> Linear(생략)\n",
        "- 이진분류 -> 1 Activation : sigmoid \n",
        "- 이진분류 -> 2 (one-hot-encoding) Activation : softmax\n",
        "- 다진분류 -> n Activation : softmax   \n",
        "\n",
        "## 모델 컴파일\n",
        "     modelName.compile(loss= , optimizer= , metrics= )\n",
        "- loss : 사용할 손실함수 (비용함수)\n",
        "     - 회귀 : MSE\n",
        "     - 이진분류 : binary_crossentropy\n",
        "     - 다진분류 : categorical_crossentropy\n",
        "- optimizer : 최적화 함수 (경사하강법의 종류)\n",
        "     - GD : 경사하강법\n",
        "     - SGD : 확률적 경사하강법\n",
        "     - MSGD : 모멘텀 확률적 경사하강법\n",
        "     - adam  \n",
        "- metrics : 평가도구 (정확도 또는 오차)\n",
        "     - 회귀 : 표기하지 않음 \n",
        "     - 분류 : accuracy\n",
        "#### 유형별 최적화\n",
        "- loss = mse(회귀), binary_crossentropy(이진분류), categorical_crossentropy(다진분류)\n",
        "- optimizer = adam (웬만하면 adam)\n",
        "- metrics = \\[\"accuracy\"](분류) / (회귀는 표시하지 않음)\n",
        "\n",
        "\n",
        "## 모델 학습\n",
        "     modelName.fit(X, y, epochs= , batch_size= )\n",
        "- epochs = 학습 횟수 (학습을 너무 많이하면 과적합 우려)\n",
        "- batch_size = 한번에 처리할 데이터 수 (몇 문제를 풀고 해답을 확인할지) (높으면 속도 느려짐)\n",
        "\n",
        "## 모델 예측\n",
        "- 첫 번째 요소\\[0]는 오차\n",
        "- 두 번째 요소\\[1]는 정확도\n",
        "     modelName.predict(X_new)\n",
        "     score = modelName.evaluate(X_new, y_new)\\[1]\n",
        "     \n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WIb_wJZaMJGx"
      },
      "source": [
        "# [실습1] 폐암환자 데이터셋을 이용하여 생존유무 예측 - 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwCg7ZD5DPSF",
        "outputId": "4841e013-352c-4682-c644-78faadeef5da"
      },
      "outputs": [],
      "source": [
        "# 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "col_name = [\"번호\", \"유형\", \"폐활량\", \"호기량\", \"상태\", \"통증\", \"객혈\",\n",
        "            \"호흡\", \"기침\", \"약화\", \"크기\", \"당뇨\", \"MI\", \"PAD\",\n",
        "            \"흡연\", \"천식\", \"나이\", \"생존\"]\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/사물지능_딥러닝_2022/data/ThoraricSurgery.csv\"\n",
        "data = pd.read_csv(file_path, header=None, index_col=0, names=col_name)  # col title이 없는 데이터 부를 땐 header=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "6xy1BCynDPUa",
        "outputId": "3fdae184-b72f-4ec4-975a-74813f79cec4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1ddc51ed-5122-44d3-aeb1-c4032ff41463\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>유형</th>\n",
              "      <th>폐활량</th>\n",
              "      <th>호기량</th>\n",
              "      <th>상태</th>\n",
              "      <th>통증</th>\n",
              "      <th>객혈</th>\n",
              "      <th>호흡</th>\n",
              "      <th>기침</th>\n",
              "      <th>약화</th>\n",
              "      <th>크기</th>\n",
              "      <th>당뇨</th>\n",
              "      <th>MI</th>\n",
              "      <th>PAD</th>\n",
              "      <th>흡연</th>\n",
              "      <th>천식</th>\n",
              "      <th>나이</th>\n",
              "      <th>생존</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>번호</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>1</td>\n",
              "      <td>3.80</td>\n",
              "      <td>2.80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2.88</td>\n",
              "      <td>2.16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>3.19</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2</td>\n",
              "      <td>3.98</td>\n",
              "      <td>3.06</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2</td>\n",
              "      <td>2.21</td>\n",
              "      <td>1.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ddc51ed-5122-44d3-aeb1-c4032ff41463')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ddc51ed-5122-44d3-aeb1-c4032ff41463 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ddc51ed-5122-44d3-aeb1-c4032ff41463');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     유형   폐활량   호기량  상태  통증  객혈  호흡  기침  약화  크기  당뇨  MI  PAD  흡연  천식  나이  생존\n",
              "번호                                                                          \n",
              "293   1  3.80  2.80   0   0   0   0   0   0  12   0   0    0   1   0  62   0\n",
              "1     2  2.88  2.16   1   0   0   0   1   1  14   0   0    0   1   0  60   0\n",
              "8     2  3.19  2.50   1   0   0   0   1   0  11   0   0    1   1   0  66   1\n",
              "14    2  3.98  3.06   2   0   0   0   1   1  14   0   0    0   1   0  80   1\n",
              "17    2  2.21  1.88   0   0   1   0   0   0  12   0   0    0   1   0  56   0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()\n",
        "# 수치형 컬럼 : 폐활량, 호기량, 나이\n",
        "# 유형 : 1, 2, 3, 4, 5, 6, 8\n",
        "# 상태 : 0, 1, 2\n",
        "# 크기 : 11, 12, 13, 14 type\n",
        "# MI(심근경색), PAD(말초동맥경화)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytce2nU4DPW_",
        "outputId": "1ed58854-54c1-4ad0-9cef-6bea58bfda4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(470, 17)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터의 구조 및 갯수\n",
        "data.shape\n",
        "\n",
        "# 데이터 갯수 : 470개\n",
        "# 특성의 수 : 16개 (종양의 유형, 크기, 폐활량, 기침정도, 흡여부 등)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ06WDbEDPZR",
        "outputId": "ab2c021c-0021-4e12-84ab-b3f3fde6e5a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "라벨 데이터의 클래스 수 :  [0 1]\n",
            "라벨 데이터의 클래스별 데이터 수 :  0    400\n",
            "1     70\n",
            "Name: 생존, dtype: int64\n",
            "유형 데이터의 클래스 수 :  [1 2 3 4 5 6 8]\n",
            "상태 데이터의 클래스 수 :  [0 1 2]\n",
            "크기 데이터의 클래스 수 :  [12 14 11 13]\n"
          ]
        }
      ],
      "source": [
        "# 라벨 데이터의 클래스의 수와 클래스별 데이터 갯수\n",
        "print(\"라벨 데이터의 클래스 수 : \", data[\"생존\"].unique())\n",
        "print(\"라벨 데이터의 클래스별 데이터 수 : \", data[\"생존\"].value_counts())\n",
        "\n",
        "print(\"유형 데이터의 클래스 수 : \", data[\"유형\"].unique())\n",
        "print(\"상태 데이터의 클래스 수 : \", data[\"상태\"].unique())\n",
        "print(\"크기 데이터의 클래스 수 : \", data[\"크기\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ntQB5X2DPcB",
        "outputId": "ed4c9049-59e8-4a6d-dbae-07b32e7cc6ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((470, 16), (470,))"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 특성 데이터와 라벨데이터로 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = data.iloc[:, :16]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=777) \n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEIXe_aEP0Ms"
      },
      "outputs": [],
      "source": [
        "# 시드 설정 (W,b) 값 초기화는 랜덤으로 시드 설정 \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "seed=0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE2pcoFFP0PJ",
        "outputId": "d60cdedb-bc7f-4f71-b60e-a9ee8dbfc22e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                144       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                544       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,929\n",
            "Trainable params: 1,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow._api.v2.config import optimizer\n",
        "# 신경망 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "model8 = Sequential()\n",
        "#입력층\n",
        "model8.add(Dense(32, input_dim=16, activation='sigmoid'))\n",
        "#은닉층\n",
        "model8.add(Dense(16, activation='sigmoid'))  #은닉층의 활성함수는 다음 층에 넘겨줄 때\n",
        "model8.add(Dense(8, activation='sigmoid'))  \n",
        "model8.add(Dense(16, activation='sigmoid'))\n",
        "model8.add(Dense(32, activation='sigmoid'))\n",
        "#출력층\n",
        "model8.add(Dense(1, activation='sigmoid'))  #출력층의 활성함수와 은닉층의 활성함수는 다르다.  출력층은 분류할 때  \n",
        "\n",
        "model8.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"accuracy\"])\n",
        "\n",
        "model8.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5YY8D8iP0Rd"
      },
      "outputs": [],
      "source": [
        "model8.fit(X_train,y_train,epochs=1000, batch_size=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWha2pD87B2m"
      },
      "source": [
        "## 모델 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yIZBe52DPej",
        "outputId": "bdbaeb82-464c-4787-c8d0-f3e9d33c5ae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8997\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7943\n",
            "Train 정확도 : 0.8996960520744324 / Test 정확도 : 0.7943262457847595\n"
          ]
        }
      ],
      "source": [
        "model8.predict(X_test)\n",
        "score0 = model8.evaluate(X_train, y_train)[1]\n",
        "score1 = model8.evaluate(X_test, y_test)[1]\n",
        "print(\"Train 정확도 :\", score0, \"/\", \"Test 정확도 :\", score1)\n",
        "# train 데이터 셋에서는 0.9의 정확도가 나오는데 \n",
        "# evaluate 찍어보면 0.8이 나오니까 과적합인듯  (층별 개수가 많이 차이나지 않도록 하는 것이 과적합 방지에 좋다. 그래도 안되면 Dropout 하면 됨)\n",
        "# 드롭아웃은 학습 과정에서 신경망의 일부를 사용하지 않는 방법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPBoZQ_6878U",
        "outputId": "50ad67cd-ee3a-474d-f0ba-0fbdcc598ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.08152937]\n",
            "[0.06387014]\n",
            "[0.07091906]\n",
            "[0.07078291]\n",
            "[0.7189824]\n",
            "[0.06543282]\n",
            "[0.06289744]\n",
            "[0.06436284]\n",
            "[0.06198619]\n"
          ]
        }
      ],
      "source": [
        "#예측\n",
        "y_pred = model8.predict(X_test)\n",
        "for i in range(1,10):\n",
        "  print(y_pred[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiG942xc7281"
      },
      "source": [
        "## 라벨 원핫인코딩한 데이터를 학습\n",
        "- 출력층의 units을 라벨의 클래스 수와 동일하게 설정\n",
        "- 출력층의 activtion을 softmax로 설정\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DALWWQD8wrrs",
        "outputId": "75473022-faaf-4234-c1da-efb8d881818a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(470, 2)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# y를 원핫인코딩\n",
        "y_en = pd.get_dummies(y)\n",
        "\n",
        "y_en.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9KgNywyzJ1Q",
        "outputId": "076473d7-2cbd-4929-b8d6-d8ce87da80f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((470, 16), (470, 2))"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "X_train2, X_test2, yen_train, yen_test = train_test_split(X, y_en, test_size=0.3, random_state=777) \n",
        "\n",
        "X.shape, y_en.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cctJh0nCzJ32"
      },
      "outputs": [],
      "source": [
        "# 시드 설정 (W,b) 값 초기화는 랜덤으로 시드 설정 \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "seed=0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee6n9RKEzJ6n",
        "outputId": "947390a2-0f56-4737-b29b-081e2f1514be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 32)                544       \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 32)                544       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,962\n",
            "Trainable params: 1,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow._api.v2.config import optimizer\n",
        "# 신경망 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "model9 = Sequential()\n",
        "#입력층\n",
        "model9.add(Dense(32, input_dim=16, activation='softmax'))\n",
        "#은닉층\n",
        "model9.add(Dense(16, activation='softmax'))  #은닉층의 활성함수는 다음 층에 넘겨줄 때\n",
        "model9.add(Dense(8, activation='softmax'))  \n",
        "model9.add(Dense(16, activation='softmax'))\n",
        "model9.add(Dense(32, activation='softmax'))\n",
        "#출력층 (라벨을 원핫 인코딩 한 경우에는 units을 라벨의 클래스 수로 설정!)\n",
        "model9.add(Dense(2, activation='softmax'))  #출력층의 활성함수와 은닉층의 활성함수는 다르다.  출력층은 분류할 때  \n",
        "\n",
        "model9.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"accuracy\"])\n",
        "\n",
        "model9.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNDzVC6VzJ84"
      },
      "outputs": [],
      "source": [
        "model9.fit(X_train2,yen_train,epochs=1000, batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUulXwaHzJ_a",
        "outputId": "f9490124-0119-4fb6-a99c-d540d81f6d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8480\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3967 - accuracy: 0.8652\n",
            "Train 정확도 : 0.848024308681488 / Test 정확도 : 0.8652482032775879\n"
          ]
        }
      ],
      "source": [
        "model9.predict(X_test2)\n",
        "score2 = model9.evaluate(X_train2, yen_train)[1]\n",
        "score3 = model9.evaluate(X_test2, yen_test)[1]\n",
        "print(\"Train 정확도 :\", score2, \"/\", \"Test 정확도 :\", score3)\n",
        "# train 데이터 셋에서는 0.9의 정확도가 나오는데 \n",
        "# evaluate 찍어보면 0.8이 나오니까 과적합인듯  (층별 개수가 많이 차이나지 않도록 하는 것이 과적합 방지에 좋다. 그래도 안되면 Dropout 하면 됨)\n",
        "# 드롭아웃은 학습 과정에서 신경망의 일부를 사용하지 않는 방법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU9mp9rrzKEI",
        "outputId": "0da0243c-df77-425a-d503-0f02acde640d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.96824664 0.03175339]\n",
            "[0.96824664 0.03175339]\n",
            "[0.96824664 0.03175339]\n",
            "[0.96824664 0.03175339]\n",
            "[0.96824664 0.03175339]\n",
            "[0.96824664 0.03175339]\n",
            "[0.96824664 0.03175339]\n",
            "[0.96824664 0.0317534 ]\n",
            "[0.96824664 0.03175339]\n"
          ]
        }
      ],
      "source": [
        "#예측\n",
        "yen_pred = model9.predict(X_test2)\n",
        "for i in range(1,10):\n",
        "  print(yen_pred[i])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zwWQjXz-Dl9T"
      },
      "source": [
        "# [실습2] wine 데이터 셋을 활용한 학습 - 회귀/분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9maPvBgzKGg",
        "outputId": "3eaa1982-5a9b-464d-e360-ddb29c5571a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/사물지능_딥러닝_2022/data/wine.csv\"\n",
        "data_wine = pd.read_csv(file_path, index_col=None)  # col title이 없는 데이터 부를 땐 header=None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "cwSmdNvgzKIr",
        "outputId": "a98fcc8a-af6f-4b26-ffb4-9fa6b381e912"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-df8aae64-7421-499a-a31b-7e58017a3fc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df8aae64-7421-499a-a31b-7e58017a3fc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-df8aae64-7421-499a-a31b-7e58017a3fc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-df8aae64-7421-499a-a31b-7e58017a3fc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "\n",
              "   alcohol  quality  type  \n",
              "0      9.4        5     1  \n",
              "1      9.8        5     1  \n",
              "2      9.8        5     1  \n",
              "3      9.8        6     1  \n",
              "4      9.4        5     1  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_wine.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7h3qKO_zKLO",
        "outputId": "c7118d7f-0c4a-47b1-e2b4-cf570c098063"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6497, 13)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_wine.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBbHCHYkzKOK",
        "outputId": "883de725-56a6-4f1c-aa96-1e771fd40e8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5 6 7 4 8 3 9]\n",
            "[1 0]\n"
          ]
        }
      ],
      "source": [
        "print(data_wine[\"quality\"].unique())\n",
        "print(data_wine[\"type\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBFS8YskETRF",
        "outputId": "db971bbd-77a3-454d-8136-c122964adc64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6497, 12), (6497,))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 특성 데이터와 라벨데이터로 분리\n",
        "X1 = data_wine.iloc[:, :-3]\n",
        "X2 = data_wine.iloc[:, -2:]\n",
        "X = pd.concat([X1, X2], axis=1)\n",
        "y = data_wine.iloc[:, -3]\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yfkiYQ_EaHn"
      },
      "source": [
        "## 회귀분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJTH8xHPETVr",
        "outputId": "c3ca2549-5d01-4759-8f75-ab4f920cd42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 24)                312       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 48)                1200      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 24)                1176      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,713\n",
            "Trainable params: 2,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 신경망 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model10 = Sequential()\n",
        "\n",
        "# 입력층\n",
        "model10.add(Dense(units=24, input_dim=12, activation=\"sigmoid\"))\n",
        "# 은닉층\n",
        "model10.add(Dense(48, activation=\"sigmoid\"))\n",
        "model10.add(Dense(24, activation=\"sigmoid\"))\n",
        "# 출력층, 회귀의 경우 units는 1로, activation은 \"linear\"를 쓰거나 생략\n",
        "model10.add(Dense(1))\n",
        "\n",
        "\n",
        "model10.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pdcv8l4nI2JN"
      },
      "outputs": [],
      "source": [
        "model10.compile(loss='mse', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBVdVpS2ETXz"
      },
      "outputs": [],
      "source": [
        "h9=model10.fit(X,y,epochs=500, batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqK9mxC8Ikf0",
        "outputId": "78a0581f-954a-4084-95d5-6aaa054d2509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 0s 2ms/step - loss: 0.6504\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 0.6628\n",
            "Train 정확성 : 0.6503934264183044 / Test 정확성 : 0.662784218788147\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDEclWCGKdCg"
      },
      "source": [
        "### 결과 시각화 하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "n0sLo6YrIkiH",
        "outputId": "30308888-c9ac-420c-d265-e73835a192c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f824fc68e10>]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 결과에서 loss 값들을 가져온다\n",
        "loss = h9.history[\"loss\"]\n",
        "\n",
        "# 반복 수\n",
        "xaxis = range(1, len(loss)+1)\n",
        "plt.plot(xaxis, loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAXiPznWMQS0"
      },
      "source": [
        "## 훈련데이터와 테스트 데이터로 분리해서 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVBWE8ZvKcST",
        "outputId": "24fa2915-65fb-45f9-b86e-66e3d574b5ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4547, 12), (1950, 12), (4547,), (1950,))"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) \n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfzeKY3uIkkb",
        "outputId": "a52ef2ac-4f97-4c84-d99d-3d760ef0e8df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 24)                312       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 48)                1200      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 24)                1176      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,713\n",
            "Trainable params: 2,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 신경망 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model11 = Sequential()\n",
        "\n",
        "# 입력층\n",
        "model11.add(Dense(units=24, input_dim=12, activation=\"sigmoid\"))\n",
        "# 은닉층\n",
        "model11.add(Dense(48, activation=\"sigmoid\"))\n",
        "model11.add(Dense(24, activation=\"sigmoid\"))\n",
        "# 출력층, 회귀의 경우 units는 1로, activation은 \"linear\"를 쓰거나 생략\n",
        "model11.add(Dense(1))\n",
        "\n",
        "\n",
        "model11.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vITI7IXZQYZL"
      },
      "outputs": [],
      "source": [
        "model11.compile(loss='mse', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHmIQv-OQYeb"
      },
      "outputs": [],
      "source": [
        "h11 = model11.fit(X_train,y_train, epochs=500, batch_size=100, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "6MbDby2dQYgg",
        "outputId": "62f113a0-e61f-418a-8a68-b6dc6cff4e19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f824f835210>]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 결과에서 loss 값들을 가져온다\n",
        "loss = h11.history[\"loss\"]\n",
        "val_loss = h11.history[\"val_loss\"]\n",
        "\n",
        "# 반복 수\n",
        "xaxis = range(1, len(loss)+1)\n",
        "plt.plot(xaxis, loss, \"r\", label=\"train\")\n",
        "plt.plot(xaxis, val_loss, \"b\", label=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhZ_TsJkIkmr",
        "outputId": "f71dbdff-438b-41e2-cb2d-bb37ff67e01a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 0s 2ms/step - loss: 0.6130\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.7325\n",
            "Train 오차 : 0.6130151748657227 / Test 오차 : 0.7325150370597839\n"
          ]
        }
      ],
      "source": [
        "score4 = model11.evaluate(X_train, y_train)\n",
        "score5 = model11.evaluate(X_test, y_test)\n",
        "print(\"Train 오차 :\", score4, \"/\", \"Test 오차 :\", score5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLRRX0BaSlrL"
      },
      "source": [
        "## 다진분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfgKd07USl2v"
      },
      "outputs": [],
      "source": [
        "# 라벨 값을 quality 컬럼 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYklrGQeSl5p",
        "outputId": "fbd4c3a4-d272-4eba-e5b9-cabfcbefc689"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((6497, 12), (6497, 7))"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 특성 데이터와 라벨데이터로 분리\n",
        "X1 = data_wine.iloc[:, :-2]\n",
        "X2 = data_wine.iloc[:, -1]\n",
        "X = pd.concat([X1, X2], axis=1)\n",
        "y = data_wine.iloc[:, -2]\n",
        "y = pd.get_dummies(y)\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drsBWB-ESl8N",
        "outputId": "ff24da01-f890-4ace-fa59-1f3a3d6ccac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4547, 12), (1950, 12), (4547, 7), (1950, 7))"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) \n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBuGIAnSSl-o",
        "outputId": "a359907c-cda0-41c8-ec0b-443c32bdbd12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 24)                312       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 48)                1200      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 24)                1176      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 7)                 175       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,863\n",
            "Trainable params: 2,863\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 신경망 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model12 = Sequential()\n",
        "\n",
        "# 입력층\n",
        "model12.add(Dense(units=24, input_dim=12, activation=\"softmax\"))\n",
        "# 은닉층\n",
        "model12.add(Dense(48, activation=\"softmax\"))\n",
        "model12.add(Dense(24, activation=\"softmax\"))\n",
        "# 출력층, 회귀의 경우 units는 1로, activation은 \"linear\"를 쓰거나 생략\n",
        "model12.add(Dense(7, activation='softmax'))\n",
        "\n",
        "\n",
        "model12.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buNLeie9SmBJ"
      },
      "outputs": [],
      "source": [
        "model12.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjD73JHsSmGP"
      },
      "outputs": [],
      "source": [
        "h12 = model12.fit(X_train,y_train, epochs=500, batch_size=100, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NVIMQkmUzzb",
        "outputId": "90c85285-e2d5-4d28-c7d8-eec671b67226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "143/143 [==============================] - 0s 2ms/step - loss: 1.0594 - accuracy: 0.5472\n",
            "61/61 [==============================] - 0s 2ms/step - loss: 1.0927 - accuracy: 0.5282\n",
            "Train 정확도 : 0.5471739768981934 / Test 정확도 : 0.528205156326294\n"
          ]
        }
      ],
      "source": [
        "score6 = model12.evaluate(X_train, y_train)[1]\n",
        "score7 = model12.evaluate(X_test, y_test)[1]\n",
        "print(\"Train 정확도 :\", score6, \"/\", \"Test 정확도 :\", score7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "AMqQV_YlUJOc",
        "outputId": "e8d905f4-bf4f-4589-a5de-73aaf1022910"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8242d01d50>]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 결과에서 accuracy 값들을 가져온다\n",
        "accuracy = h12.history[\"accuracy\"]\n",
        "val_accuracy = h12.history[\"val_accuracy\"]\n",
        "\n",
        "# 반복 수\n",
        "xaxis = range(1, len(accuracy)+1)\n",
        "plt.plot(xaxis, accuracy, \"r\", label=\"train_accuracy\")\n",
        "plt.plot(xaxis, val_accuracy, \"b\", label=\"test_accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "LENQGrWFUbe1",
        "outputId": "b3914440-4dc5-476b-da76-854110d4f59c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8242d1f710>]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 학습 결과에서 loss 값들을 가져온다\n",
        "loss = h12.history[\"loss\"]\n",
        "val_loss = h12.history[\"val_loss\"]\n",
        "\n",
        "# 반복 수\n",
        "xaxis = range(1, len(loss)+1)\n",
        "plt.plot(xaxis, loss, \"g\", label=\"train_loss\")\n",
        "plt.plot(xaxis, val_loss, \"y\", label=\"test_loss\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p4WSOoEzaWjs"
      },
      "source": [
        "# [실습3] 보스턴 집값 분석 - 회귀"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- CRIM : 인구 1인당 범죄 발생 수\n",
        "- ZN : 25,000평방 피트 이상의 주거 구역 비중\n",
        "- INDUS : 소매업 외 상업이 차지하는 면적 비율\n",
        "- CHAS : 찰스강 위치 변수 (1: 강 주변, 0: 이외)\n",
        "- NOX : 일산화질소 농도\n",
        "- RM : 집의 평균 방 수\n",
        "- AGE : 1940년 이전 지어진 비율\n",
        "- DIS : 5가지 보스턴 시 고용 시설까지의 거리\n",
        "- RAD : 순환고속도로의 접근 용이성\n",
        "- TAX : 10,000달러 당 부동산 세율 총계\n",
        "- PTRATIO : 지역별 학생과 교사 비율\n",
        "- B : 지역별 흑인 비율\n",
        "- LSTAT : 급여가 낮은 직업에 종사하는 인구 비율 (%)\n",
        "- 가격 (단위 : 1,000달러)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5OlGwKzWWxh",
        "outputId": "fa6a3795-f514-4388-80d2-6079b295ef82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "((404, 13), (102, 13), (404,), (102,))"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWNHsNKEWWz0",
        "outputId": "921eb67a-8117-4c8e-d409-63737e2c9f3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 32)                448       \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,673\n",
            "Trainable params: 4,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 신경망 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model01 = Sequential()\n",
        "\n",
        "# 입력층\n",
        "model01.add(Dense(units=32, input_dim=13, activation=\"sigmoid\"))\n",
        "# 은닉층\n",
        "model01.add(Dense(64, activation=\"sigmoid\"))\n",
        "model01.add(Dense(32, activation=\"sigmoid\"))\n",
        "# 출력층, 회귀의 경우 units는 1로, activation은 \"linear\"를 쓰거나 생략\n",
        "model01.add(Dense(1))\n",
        "\n",
        "\n",
        "model01.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZd1adPHWW2R"
      },
      "outputs": [],
      "source": [
        "model01.compile(loss='mse', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7B6UzmoWW4v",
        "outputId": "d8707fdd-2db1-46be-9226-41e76aca7c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 254.0765 - val_loss: 269.7002\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 252.3808 - val_loss: 267.9476\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 250.7141 - val_loss: 266.1719\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 249.0065 - val_loss: 264.4058\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 247.3633 - val_loss: 262.6545\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 245.6929 - val_loss: 260.9492\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 244.0777 - val_loss: 259.2499\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 242.4578 - val_loss: 257.5656\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 240.8603 - val_loss: 255.8427\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 239.2428 - val_loss: 254.1222\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 237.6258 - val_loss: 252.4579\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 236.0220 - val_loss: 250.7641\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 234.4454 - val_loss: 249.1368\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 232.9068 - val_loss: 247.4834\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 231.3391 - val_loss: 245.8350\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 229.7756 - val_loss: 244.2668\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 228.3239 - val_loss: 242.7319\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 226.8495 - val_loss: 241.1530\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 225.3314 - val_loss: 239.5333\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 223.8293 - val_loss: 237.9592\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 222.3732 - val_loss: 236.4123\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 220.9099 - val_loss: 234.9060\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 219.4820 - val_loss: 233.4463\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 218.1140 - val_loss: 231.9461\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 216.7125 - val_loss: 230.4819\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 215.3205 - val_loss: 229.0409\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 213.9743 - val_loss: 227.5787\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 212.5786 - val_loss: 226.1146\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 211.2137 - val_loss: 224.6867\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 209.8603 - val_loss: 223.2329\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 208.4916 - val_loss: 221.8164\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 207.1817 - val_loss: 220.4857\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 205.9321 - val_loss: 219.1609\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 204.7192 - val_loss: 217.8887\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 203.5242 - val_loss: 216.6450\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 202.3270 - val_loss: 215.3690\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 201.1323 - val_loss: 214.0972\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 199.9253 - val_loss: 212.8128\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 198.7065 - val_loss: 211.4567\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 197.3988 - val_loss: 210.1045\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 196.1827 - val_loss: 208.7910\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 194.9474 - val_loss: 207.5140\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 193.7698 - val_loss: 206.2492\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 192.5814 - val_loss: 204.9899\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 191.3910 - val_loss: 203.7365\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 190.2290 - val_loss: 202.4934\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 189.0649 - val_loss: 201.3091\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 187.9666 - val_loss: 200.1539\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 186.8826 - val_loss: 198.9400\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 185.7446 - val_loss: 197.7706\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 184.6685 - val_loss: 196.6415\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 183.5963 - val_loss: 195.4875\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 182.5257 - val_loss: 194.3478\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 181.4666 - val_loss: 193.2192\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 180.4028 - val_loss: 192.0677\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 179.3155 - val_loss: 190.8674\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 178.1856 - val_loss: 189.6422\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 177.0238 - val_loss: 188.4158\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 175.9010 - val_loss: 187.2289\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 174.8110 - val_loss: 186.1157\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 173.8019 - val_loss: 185.0341\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 172.7598 - val_loss: 183.8603\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 171.6737 - val_loss: 182.6695\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 170.5619 - val_loss: 181.5454\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 169.5235 - val_loss: 180.4557\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 168.5156 - val_loss: 179.3512\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 167.5140 - val_loss: 178.3025\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 166.5236 - val_loss: 177.2231\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 165.5378 - val_loss: 176.1695\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 164.5336 - val_loss: 175.1072\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 163.5686 - val_loss: 174.0861\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 162.6059 - val_loss: 173.0371\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 161.6338 - val_loss: 172.0584\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 160.7561 - val_loss: 171.1248\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 159.8810 - val_loss: 170.1823\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 158.9998 - val_loss: 169.1692\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 158.0825 - val_loss: 168.2340\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 157.2323 - val_loss: 167.3228\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 156.3786 - val_loss: 166.3972\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 155.5241 - val_loss: 165.5287\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 154.7368 - val_loss: 164.6589\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 153.9151 - val_loss: 163.8017\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 153.1490 - val_loss: 162.9454\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 152.3624 - val_loss: 162.1068\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 151.5793 - val_loss: 161.2819\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 150.8215 - val_loss: 160.4333\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 150.0456 - val_loss: 159.5971\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 149.2635 - val_loss: 158.7442\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 148.4768 - val_loss: 157.8782\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 147.6815 - val_loss: 157.0489\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 146.9277 - val_loss: 156.2688\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 146.2140 - val_loss: 155.4830\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 145.4754 - val_loss: 154.6875\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 144.7358 - val_loss: 153.8311\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 143.9398 - val_loss: 152.9613\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 143.1606 - val_loss: 152.1482\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 142.4229 - val_loss: 151.3415\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 141.6793 - val_loss: 150.5480\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 140.9616 - val_loss: 149.7913\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 140.2877 - val_loss: 149.0497\n"
          ]
        }
      ],
      "source": [
        "h01=model01.fit(X_train,y_train,epochs=100, batch_size=100, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "fBhjq995WW6t",
        "outputId": "71379f7d-5fef-4fba-df6b-ef4c18b8059d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8240340150>]"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 결과에서 accuracy 값들을 가져온다\n",
        "loss = h01.history[\"loss\"]\n",
        "val_loss = h01.history[\"val_loss\"]\n",
        "\n",
        "# 반복 수\n",
        "xaxis = range(1, len(loss)+1)\n",
        "plt.plot(xaxis, loss, \"r\", label=\"train_loss\")\n",
        "plt.plot(xaxis, val_loss, \"b\", label=\"test_loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W3ZQ2UFeZAy"
      },
      "source": [
        "# [실습4] 유방암 데이터 분석 - 이진분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNVXcJvrWW_Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "cancer = load_breast_cancer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPzK2DvJgeJ7",
        "outputId": "a5af2638-a615-41e3-fcf9-9bfa80eef18c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((569, 30), (569,))"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X2=cancer.data\n",
        "y2=cancer.target\n",
        "X2.shape, y2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvwH2dY6WXEe",
        "outputId": "53e7562f-a2a3-4200-8b43-3a7bc9497c27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cancer.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJhYpVdgWXG8",
        "outputId": "a4b87637-4e9e-4ff8-facd-887af074ede1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((398, 30), (398,), (171, 30), (171,))"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train2, y_train2, X_test2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=777 )\n",
        "\n",
        "X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnNLAC8cfxR9",
        "outputId": "00461095-0840-4721-bfd8-b1a27118233c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_40 (Dense)            (None, 64)                1984      \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,609\n",
            "Trainable params: 4,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow._api.v2.config import optimizer\n",
        "# 신경망 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model02 = Sequential()\n",
        "#입력층\n",
        "model02.add(Dense(64, input_dim=30, activation='sigmoid'))\n",
        "#은닉층\n",
        "model02.add(Dense(32, activation='sigmoid')) \n",
        "model02.add(Dense(16, activation='sigmoid'))\n",
        "#출력층\n",
        "model02.add(Dense(1, activation='sigmoid'))  \n",
        "\n",
        "model02.compile(loss='binary_crossentropy', optimizer='adam', metrics = [\"accuracy\"])\n",
        "\n",
        "model02.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvT2DBVhiuAu",
        "outputId": "fa947a5b-4746-4eb4-94d3-83cca2f272e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((398, 30), (398,), (171, 30), (171,))"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train2.shape, X_test2.shape, y_train2.shape, y_test2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot8_fvELhXj3"
      },
      "outputs": [],
      "source": [
        "h02 = model02.fit(X_train2, X_test2, epochs=100, batch_size=20, validation_data=(y_train2, y_test2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUXBdKTHhXmB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "56vIwyMthXpg",
        "outputId": "892c04e4-0c97-4dc9-aee0-5c515e0ece0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f824dec3e10>]"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 결과에서 accuracy 값들을 가져온다\n",
        "accuracy = h02.history[\"accuracy\"]\n",
        "val_accuracy = h02.history[\"val_accuracy\"]\n",
        "\n",
        "# 반복 수\n",
        "xaxis = range(1, len(accuracy)+1)\n",
        "plt.plot(xaxis, accuracy, \"r\", label=\"train_accuracy\")\n",
        "plt.plot(xaxis, val_accuracy, \"b\", label=\"test_accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w65TtuVhXr1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UoQiRmlaa7n"
      },
      "source": [
        "# [실습5] 붓꽃 데이터 분석 - 다중분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8CQXS1ZeRxm"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMcMyCz2eR1Z"
      },
      "outputs": [],
      "source": [
        "X3 = iris.data\n",
        "y3 = iris.target\n",
        "y3 = pd.get_dummies(y3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lzpscRxeR3X",
        "outputId": "09897ce9-7b71-42aa-9981-96c0e644d89d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((120, 4), (30, 4), (120, 3), (30, 3))"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=777 )\n",
        "\n",
        "X_train3.shape, X_test3.shape, y_train3.shape, y_test3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T0-b7H5jxH4",
        "outputId": "1b9459f7-0acb-4a46-b09a-b30d1b2951f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_56 (Dense)            (None, 8)                 40        \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 16)                144       \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 3)                 27        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 347\n",
            "Trainable params: 347\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 신경망 설계\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model03 = Sequential()\n",
        "\n",
        "# 입력층\n",
        "model03.add(Dense(units=8, input_dim=4, activation=\"softmax\"))\n",
        "# 은닉층\n",
        "model03.add(Dense(16, activation=\"softmax\"))\n",
        "model03.add(Dense(8, activation=\"softmax\"))\n",
        "# 출력층, 회귀의 경우 units는 1로, activation은 \"linear\"를 쓰거나 생략\n",
        "model03.add(Dense(3, activation='softmax'))\n",
        "\n",
        "\n",
        "model03.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkHJ9fMjjxKA"
      },
      "outputs": [],
      "source": [
        "model03.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQO1OOLPjxMp"
      },
      "outputs": [],
      "source": [
        "h03 = model03.fit(X_train3,y_train3, epochs=1000, batch_size=100, validation_data=(X_test3, y_test3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "p9JIyjQQjxPL",
        "outputId": "d5b44ad0-93cd-4890-822e-1c36120c0da3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f824c53c290>]"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 결과에서 accuracy 값들을 가져온다\n",
        "accuracy = h03.history[\"accuracy\"]\n",
        "val_accuracy = h03.history[\"val_accuracy\"]\n",
        "\n",
        "# 반복 수\n",
        "xaxis = range(1, len(accuracy)+1)\n",
        "plt.plot(xaxis, accuracy, \"r\", label=\"train_accuracy\")\n",
        "plt.plot(xaxis, val_accuracy, \"b\", label=\"test_accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "46e27ede752268be201d36b7fbc2802b29a11b0bb095abacecc6c0428b93624a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
